{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import os\n",
        "import csv\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from zipfile import ZipFile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "UIl9eyBWOAX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyvZsYa5JCWj",
        "outputId": "2434f7a1-6bd1-4adf-9fce-5a32b02a467c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset is extracted successfully\n"
          ]
        }
      ],
      "source": [
        "#RAVDESS Emotional speech audio\n",
        "# https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio\n",
        "\n",
        "data='/content/audio_speech_actors_01-24.zip'\n",
        "with ZipFile(data,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('dataset is extracted successfully')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read a sample audio using librosa\n",
        "audio_file_path='/content/audio_speech_actors_01-24/Actor_06/03-01-06-02-01-02-06.wav'\n",
        "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
      ],
      "metadata": {
        "id": "L1QQ-OZNJL0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion class mapping (from ID to name)\n",
        "emotion_mapping = {\n",
        "    '01': 'neutral',\n",
        "    '02': 'calm',\n",
        "    '03': 'happy',\n",
        "    '04': 'sad',\n",
        "    '05': 'angry',\n",
        "    '06': 'fearful',\n",
        "    '07': 'disgust',\n",
        "    '08': 'surprised'\n",
        "}\n",
        "\n",
        "# Folder containing the actor directories\n",
        "parent_folder = 'audio_speech_actors_01-24'  # Adjust this path to your folder\n",
        "\n",
        "# Prepare to write the CSV file\n",
        "csv_filename = 'audio_emotion_data.csv'\n",
        "\n",
        "# Open the CSV file in write mode\n",
        "with open(csv_filename, mode='w', newline='') as csvfile:\n",
        "    # Initialize CSV writer\n",
        "    fieldnames = ['Filename', 'Folder', 'Class ID', 'Class Name']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write header\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Loop over each actor folder (Actor 01 to Actor 24)\n",
        "    for actor_folder in os.listdir(parent_folder):\n",
        "        actor_folder_path = os.path.join(parent_folder, actor_folder)\n",
        "\n",
        "        # Ensure we're only looking at directories\n",
        "        if os.path.isdir(actor_folder_path):\n",
        "            # Loop through each file in the actor's folder\n",
        "            for file in os.listdir(actor_folder_path):\n",
        "                if file.endswith('.wav'):\n",
        "                    # Split the filename by '-' and extract the required details\n",
        "                    parts = file.split('-')\n",
        "\n",
        "                    # Extract information from the filename\n",
        "                    modality = parts[0]  # Modality (01 = audio-only, etc.)\n",
        "                    speech = parts[1]    # Speech (01 = speech)\n",
        "                    emotion_class_id = parts[2]  # Emotion (class ID, e.g., 06 for fearful)\n",
        "                    emotion_class_name = emotion_mapping.get(emotion_class_id, 'Unknown')\n",
        "                    emotional_intensity = parts[3]  # Emotional intensity (01 = normal)\n",
        "                    statement = parts[4]  # Statement (01 = \"Kids are talking...\")\n",
        "                    repetition = parts[5]  # Repetition (01 = 1st repetition)\n",
        "                    actor_id = parts[6]  # Actor ID (01 to 24)\n",
        "\n",
        "                    # Write row to CSV\n",
        "                    writer.writerow({\n",
        "                        'Filename': file,\n",
        "                        'Folder': actor_folder,\n",
        "                        'Class ID': emotion_class_id,\n",
        "                        'Class Name': emotion_class_name\n",
        "                    })\n",
        "\n",
        "print(f\"CSV file '{csv_filename}' has been created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbUdzfmpJOf-",
        "outputId": "b0bc9833-4f30-4689-82d1-fdfa258f268b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file 'audio_emotion_data.csv' has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "audio_df=pd.read_csv('audio_emotion_data.csv')\n",
        "audio_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mfa2IqLcJRH2",
        "outputId": "32352446-e1b0-498b-ec17-e862c92f648e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Filename    Folder  Class ID Class Name\n",
              "0  03-01-02-01-02-01-01.wav  Actor_01         2       calm\n",
              "1  03-01-08-01-02-02-01.wav  Actor_01         8  surprised\n",
              "2  03-01-05-01-01-01-01.wav  Actor_01         5      angry\n",
              "3  03-01-07-02-02-02-01.wav  Actor_01         7    disgust\n",
              "4  03-01-03-02-02-02-01.wav  Actor_01         3      happy\n",
              "5  03-01-01-01-02-02-01.wav  Actor_01         1    neutral\n",
              "6  03-01-02-02-02-01-01.wav  Actor_01         2       calm\n",
              "7  03-01-08-01-01-01-01.wav  Actor_01         8  surprised\n",
              "8  03-01-08-02-02-01-01.wav  Actor_01         8  surprised\n",
              "9  03-01-04-02-02-02-01.wav  Actor_01         4        sad"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab6d8a9f-2dbf-4c7f-bc65-907f4d9042c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Folder</th>\n",
              "      <th>Class ID</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03-01-02-01-02-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>2</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03-01-08-01-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>8</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03-01-05-01-01-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>5</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>03-01-07-02-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>7</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>03-01-03-02-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>3</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>03-01-01-01-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>03-01-02-02-02-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>2</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>03-01-08-01-01-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>8</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>03-01-08-02-02-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>8</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>03-01-04-02-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>4</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab6d8a9f-2dbf-4c7f-bc65-907f4d9042c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab6d8a9f-2dbf-4c7f-bc65-907f4d9042c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab6d8a9f-2dbf-4c7f-bc65-907f4d9042c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a93bafbe-90d2-49a4-84d0-d6a2a6deba36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a93bafbe-90d2-49a4-84d0-d6a2a6deba36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a93bafbe-90d2-49a4-84d0-d6a2a6deba36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "audio_df",
              "summary": "{\n  \"name\": \"audio_df\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          \"03-01-06-01-01-02-19.wav\",\n          \"03-01-05-02-01-01-06.wav\",\n          \"03-01-03-01-02-01-02.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Folder\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Actor_23\",\n          \"Actor_18\",\n          \"Actor_01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"surprised\",\n          \"neutral\",\n          \"calm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_df['Class Name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "qNrqmGGMJSvf",
        "outputId": "a45c74ed-5d08-4f0b-e851-72fad09a0b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class Name\n",
              "calm         192\n",
              "surprised    192\n",
              "angry        192\n",
              "disgust      192\n",
              "happy        192\n",
              "sad          192\n",
              "fearful      192\n",
              "neutral       96\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class Name</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>calm</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprised</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fearful</th>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_df['Class Name'].isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5cz_rMVPN_6",
        "outputId": "1b5acb6e-a7bc-435d-a194-6e4795124abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dataset_path='/content/audio_speech_actors_01-24'\n",
        "metadata=pd.read_csv('audio_emotion_data.csv')\n",
        "metadata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vZWNJAKNJVQA",
        "outputId": "fe87fd65-ae4f-4a84-90d5-0072dcf45885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Filename    Folder  Class ID Class Name\n",
              "0  03-01-02-01-02-01-01.wav  Actor_01         2       calm\n",
              "1  03-01-08-01-02-02-01.wav  Actor_01         8  surprised\n",
              "2  03-01-05-01-01-01-01.wav  Actor_01         5      angry\n",
              "3  03-01-07-02-02-02-01.wav  Actor_01         7    disgust\n",
              "4  03-01-03-02-02-02-01.wav  Actor_01         3      happy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b64e4e62-09e4-458d-bd22-df7a31e248d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Folder</th>\n",
              "      <th>Class ID</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03-01-02-01-02-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>2</td>\n",
              "      <td>calm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03-01-08-01-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>8</td>\n",
              "      <td>surprised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03-01-05-01-01-01-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>5</td>\n",
              "      <td>angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>03-01-07-02-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>7</td>\n",
              "      <td>disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>03-01-03-02-02-02-01.wav</td>\n",
              "      <td>Actor_01</td>\n",
              "      <td>3</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b64e4e62-09e4-458d-bd22-df7a31e248d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b64e4e62-09e4-458d-bd22-df7a31e248d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b64e4e62-09e4-458d-bd22-df7a31e248d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85450917-346a-44b3-bb08-084546292773\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85450917-346a-44b3-bb08-084546292773')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85450917-346a-44b3-bb08-084546292773 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata",
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 1440,\n  \"fields\": [\n    {\n      \"column\": \"Filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1440,\n        \"samples\": [\n          \"03-01-06-01-01-02-19.wav\",\n          \"03-01-05-02-01-01-06.wav\",\n          \"03-01-03-01-02-01-02.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Folder\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Actor_23\",\n          \"Actor_18\",\n          \"Actor_01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"surprised\",\n          \"neutral\",\n          \"calm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction Function\n",
        "def extract_features(file):\n",
        "    audio, sample_rate = librosa.load(file, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled = np.mean(mfccs.T, axis=0)  # Take the mean of MFCCs over time\n",
        "    return mfccs_scaled"
      ],
      "metadata": {
        "id": "YADDg8rSJlA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Features and Labels\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for index_num, row in metadata.iterrows():\n",
        "    file_name = os.path.join(os.path.abspath(audio_dataset_path), str(row[\"Folder\"]), str(row[\"Filename\"]))\n",
        "    class_label = row[\"Class Name\"]\n",
        "    try:\n",
        "        features_ = extract_features(file_name)\n",
        "        features.append(features_)\n",
        "        labels.append(class_label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error encountered while parsing file: {file_name}, Error: {e}\")\n",
        "\n",
        "# Convert to Numpy Arrays\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Encode Labels\n",
        "labelencoder = LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "\n",
        "# Class Weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# One-Hot Encoding of Labels\n",
        "y = pd.get_dummies(y).values"
      ],
      "metadata": {
        "id": "ZDdsrikKJq6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ANN Model\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Hidden Layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(y_train.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxgJCR7OJ0Dl",
        "outputId": "bcca62ee-c226-4c97-a30e-d31895e6c80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile Model\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    batch_size=32,\n",
        "    epochs=650,\n",
        "    validation_split=0.1,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stopping, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxksvvSaJ3EJ",
        "outputId": "f7099d59-33b2-40fa-dcb8-47750c73ec6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 155ms/step - accuracy: 0.1295 - loss: 3.2796 - val_accuracy: 0.1293 - val_loss: 2.0972 - learning_rate: 1.0000e-04\n",
            "Epoch 2/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1337 - loss: 3.2715 - val_accuracy: 0.1293 - val_loss: 2.1054 - learning_rate: 1.0000e-04\n",
            "Epoch 3/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1395 - loss: 3.2729 - val_accuracy: 0.1379 - val_loss: 2.1045 - learning_rate: 1.0000e-04\n",
            "Epoch 4/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1434 - loss: 3.1443 - val_accuracy: 0.1466 - val_loss: 2.0963 - learning_rate: 1.0000e-04\n",
            "Epoch 5/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1368 - loss: 3.0941 - val_accuracy: 0.1724 - val_loss: 2.0800 - learning_rate: 1.0000e-04\n",
            "Epoch 6/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1241 - loss: 3.0290 - val_accuracy: 0.1638 - val_loss: 2.0615 - learning_rate: 1.0000e-04\n",
            "Epoch 7/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1665 - loss: 3.1023 - val_accuracy: 0.1810 - val_loss: 2.0437 - learning_rate: 1.0000e-04\n",
            "Epoch 8/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1424 - loss: 3.0522 - val_accuracy: 0.1810 - val_loss: 2.0240 - learning_rate: 1.0000e-04\n",
            "Epoch 9/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1462 - loss: 3.1161 - val_accuracy: 0.1983 - val_loss: 2.0025 - learning_rate: 1.0000e-04\n",
            "Epoch 10/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1423 - loss: 2.8832 - val_accuracy: 0.2069 - val_loss: 1.9787 - learning_rate: 1.0000e-04\n",
            "Epoch 11/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1250 - loss: 2.8975 - val_accuracy: 0.2586 - val_loss: 1.9576 - learning_rate: 1.0000e-04\n",
            "Epoch 12/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1626 - loss: 2.8246 - val_accuracy: 0.2931 - val_loss: 1.9432 - learning_rate: 1.0000e-04\n",
            "Epoch 13/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1292 - loss: 2.8960 - val_accuracy: 0.3017 - val_loss: 1.9287 - learning_rate: 1.0000e-04\n",
            "Epoch 14/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1847 - loss: 2.8018 - val_accuracy: 0.3103 - val_loss: 1.9091 - learning_rate: 1.0000e-04\n",
            "Epoch 15/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1860 - loss: 2.6813 - val_accuracy: 0.3190 - val_loss: 1.8916 - learning_rate: 1.0000e-04\n",
            "Epoch 16/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1857 - loss: 2.7021 - val_accuracy: 0.3362 - val_loss: 1.8691 - learning_rate: 1.0000e-04\n",
            "Epoch 17/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2006 - loss: 2.6212 - val_accuracy: 0.3448 - val_loss: 1.8469 - learning_rate: 1.0000e-04\n",
            "Epoch 18/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1608 - loss: 2.7248 - val_accuracy: 0.3534 - val_loss: 1.8340 - learning_rate: 1.0000e-04\n",
            "Epoch 19/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2036 - loss: 2.6183 - val_accuracy: 0.3534 - val_loss: 1.8238 - learning_rate: 1.0000e-04\n",
            "Epoch 20/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2101 - loss: 2.5133 - val_accuracy: 0.3707 - val_loss: 1.8144 - learning_rate: 1.0000e-04\n",
            "Epoch 21/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2049 - loss: 2.5905 - val_accuracy: 0.3621 - val_loss: 1.8046 - learning_rate: 1.0000e-04\n",
            "Epoch 22/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1831 - loss: 2.5500 - val_accuracy: 0.3621 - val_loss: 1.8015 - learning_rate: 1.0000e-04\n",
            "Epoch 23/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1960 - loss: 2.5674 - val_accuracy: 0.3707 - val_loss: 1.7911 - learning_rate: 1.0000e-04\n",
            "Epoch 24/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 2.6052 - val_accuracy: 0.3621 - val_loss: 1.7805 - learning_rate: 1.0000e-04\n",
            "Epoch 25/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2173 - loss: 2.4906 - val_accuracy: 0.3534 - val_loss: 1.7720 - learning_rate: 1.0000e-04\n",
            "Epoch 26/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2141 - loss: 2.4418 - val_accuracy: 0.3879 - val_loss: 1.7605 - learning_rate: 1.0000e-04\n",
            "Epoch 27/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2149 - loss: 2.3982 - val_accuracy: 0.3793 - val_loss: 1.7504 - learning_rate: 1.0000e-04\n",
            "Epoch 28/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2277 - loss: 2.4274 - val_accuracy: 0.3879 - val_loss: 1.7435 - learning_rate: 1.0000e-04\n",
            "Epoch 29/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2128 - loss: 2.5348 - val_accuracy: 0.3793 - val_loss: 1.7350 - learning_rate: 1.0000e-04\n",
            "Epoch 30/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2010 - loss: 2.3882 - val_accuracy: 0.3793 - val_loss: 1.7303 - learning_rate: 1.0000e-04\n",
            "Epoch 31/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2187 - loss: 2.4706 - val_accuracy: 0.4052 - val_loss: 1.7233 - learning_rate: 1.0000e-04\n",
            "Epoch 32/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2136 - loss: 2.3727 - val_accuracy: 0.4052 - val_loss: 1.7138 - learning_rate: 1.0000e-04\n",
            "Epoch 33/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1993 - loss: 2.3086 - val_accuracy: 0.4052 - val_loss: 1.7034 - learning_rate: 1.0000e-04\n",
            "Epoch 34/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2115 - loss: 2.4816 - val_accuracy: 0.3879 - val_loss: 1.6937 - learning_rate: 1.0000e-04\n",
            "Epoch 35/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2618 - loss: 2.2347 - val_accuracy: 0.3966 - val_loss: 1.6816 - learning_rate: 1.0000e-04\n",
            "Epoch 36/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 2.3517 - val_accuracy: 0.3966 - val_loss: 1.6767 - learning_rate: 1.0000e-04\n",
            "Epoch 37/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2243 - loss: 2.3893 - val_accuracy: 0.3793 - val_loss: 1.6740 - learning_rate: 1.0000e-04\n",
            "Epoch 38/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2146 - loss: 2.3696 - val_accuracy: 0.3793 - val_loss: 1.6669 - learning_rate: 1.0000e-04\n",
            "Epoch 39/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2341 - loss: 2.2691 - val_accuracy: 0.3879 - val_loss: 1.6585 - learning_rate: 1.0000e-04\n",
            "Epoch 40/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2248 - loss: 2.2921 - val_accuracy: 0.3879 - val_loss: 1.6557 - learning_rate: 1.0000e-04\n",
            "Epoch 41/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2447 - loss: 2.2197 - val_accuracy: 0.3879 - val_loss: 1.6490 - learning_rate: 1.0000e-04\n",
            "Epoch 42/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2591 - loss: 2.2331 - val_accuracy: 0.3879 - val_loss: 1.6413 - learning_rate: 1.0000e-04\n",
            "Epoch 43/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2412 - loss: 2.2252 - val_accuracy: 0.3793 - val_loss: 1.6381 - learning_rate: 1.0000e-04\n",
            "Epoch 44/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2484 - loss: 2.2374 - val_accuracy: 0.3793 - val_loss: 1.6356 - learning_rate: 1.0000e-04\n",
            "Epoch 45/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2816 - loss: 2.1488 - val_accuracy: 0.3879 - val_loss: 1.6334 - learning_rate: 1.0000e-04\n",
            "Epoch 46/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2807 - loss: 2.1026 - val_accuracy: 0.3793 - val_loss: 1.6306 - learning_rate: 1.0000e-04\n",
            "Epoch 47/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 2.2200 - val_accuracy: 0.3793 - val_loss: 1.6276 - learning_rate: 1.0000e-04\n",
            "Epoch 48/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2457 - loss: 2.2452 - val_accuracy: 0.3793 - val_loss: 1.6275 - learning_rate: 1.0000e-04\n",
            "Epoch 49/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2507 - loss: 2.1499 - val_accuracy: 0.3879 - val_loss: 1.6182 - learning_rate: 1.0000e-04\n",
            "Epoch 50/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2587 - loss: 2.1541 - val_accuracy: 0.4138 - val_loss: 1.6148 - learning_rate: 1.0000e-04\n",
            "Epoch 51/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2309 - loss: 2.1545 - val_accuracy: 0.4052 - val_loss: 1.6067 - learning_rate: 1.0000e-04\n",
            "Epoch 52/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2677 - loss: 2.1963 - val_accuracy: 0.4052 - val_loss: 1.6019 - learning_rate: 1.0000e-04\n",
            "Epoch 53/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2661 - loss: 2.1524 - val_accuracy: 0.4052 - val_loss: 1.5994 - learning_rate: 1.0000e-04\n",
            "Epoch 54/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3171 - loss: 2.0923 - val_accuracy: 0.3966 - val_loss: 1.5949 - learning_rate: 1.0000e-04\n",
            "Epoch 55/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2525 - loss: 2.1378 - val_accuracy: 0.4138 - val_loss: 1.5898 - learning_rate: 1.0000e-04\n",
            "Epoch 56/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2478 - loss: 2.2050 - val_accuracy: 0.4138 - val_loss: 1.5864 - learning_rate: 1.0000e-04\n",
            "Epoch 57/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2843 - loss: 2.1423 - val_accuracy: 0.4138 - val_loss: 1.5816 - learning_rate: 1.0000e-04\n",
            "Epoch 58/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2443 - loss: 2.1253 - val_accuracy: 0.4138 - val_loss: 1.5793 - learning_rate: 1.0000e-04\n",
            "Epoch 59/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2555 - loss: 2.1568 - val_accuracy: 0.4310 - val_loss: 1.5736 - learning_rate: 1.0000e-04\n",
            "Epoch 60/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2720 - loss: 2.0680 - val_accuracy: 0.4310 - val_loss: 1.5736 - learning_rate: 1.0000e-04\n",
            "Epoch 61/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2799 - loss: 2.1168 - val_accuracy: 0.4224 - val_loss: 1.5699 - learning_rate: 1.0000e-04\n",
            "Epoch 62/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2480 - loss: 2.0610 - val_accuracy: 0.4052 - val_loss: 1.5680 - learning_rate: 1.0000e-04\n",
            "Epoch 63/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2868 - loss: 1.9297 - val_accuracy: 0.3966 - val_loss: 1.5654 - learning_rate: 1.0000e-04\n",
            "Epoch 64/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2582 - loss: 2.0884 - val_accuracy: 0.4052 - val_loss: 1.5602 - learning_rate: 1.0000e-04\n",
            "Epoch 65/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2950 - loss: 2.0881 - val_accuracy: 0.4138 - val_loss: 1.5548 - learning_rate: 1.0000e-04\n",
            "Epoch 66/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2699 - loss: 2.0767 - val_accuracy: 0.4224 - val_loss: 1.5467 - learning_rate: 1.0000e-04\n",
            "Epoch 67/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3148 - loss: 1.9391 - val_accuracy: 0.4224 - val_loss: 1.5441 - learning_rate: 1.0000e-04\n",
            "Epoch 68/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2653 - loss: 1.9781 - val_accuracy: 0.4224 - val_loss: 1.5409 - learning_rate: 1.0000e-04\n",
            "Epoch 69/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2886 - loss: 2.0502 - val_accuracy: 0.4310 - val_loss: 1.5350 - learning_rate: 1.0000e-04\n",
            "Epoch 70/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 1.9311 - val_accuracy: 0.4483 - val_loss: 1.5317 - learning_rate: 1.0000e-04\n",
            "Epoch 71/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3152 - loss: 1.9390 - val_accuracy: 0.4397 - val_loss: 1.5273 - learning_rate: 1.0000e-04\n",
            "Epoch 72/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2987 - loss: 1.9837 - val_accuracy: 0.4483 - val_loss: 1.5223 - learning_rate: 1.0000e-04\n",
            "Epoch 73/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2797 - loss: 2.0208 - val_accuracy: 0.4483 - val_loss: 1.5196 - learning_rate: 1.0000e-04\n",
            "Epoch 74/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3039 - loss: 1.9857 - val_accuracy: 0.4483 - val_loss: 1.5154 - learning_rate: 1.0000e-04\n",
            "Epoch 75/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2933 - loss: 1.9857 - val_accuracy: 0.4569 - val_loss: 1.5126 - learning_rate: 1.0000e-04\n",
            "Epoch 76/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3090 - loss: 1.9065 - val_accuracy: 0.4569 - val_loss: 1.5086 - learning_rate: 1.0000e-04\n",
            "Epoch 77/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3055 - loss: 1.9231 - val_accuracy: 0.4741 - val_loss: 1.5022 - learning_rate: 1.0000e-04\n",
            "Epoch 78/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3131 - loss: 1.8901 - val_accuracy: 0.4741 - val_loss: 1.4989 - learning_rate: 1.0000e-04\n",
            "Epoch 79/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2914 - loss: 1.8888 - val_accuracy: 0.4655 - val_loss: 1.4974 - learning_rate: 1.0000e-04\n",
            "Epoch 80/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3058 - loss: 1.8697 - val_accuracy: 0.4569 - val_loss: 1.4918 - learning_rate: 1.0000e-04\n",
            "Epoch 81/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3157 - loss: 1.8361 - val_accuracy: 0.4655 - val_loss: 1.4937 - learning_rate: 1.0000e-04\n",
            "Epoch 82/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3124 - loss: 1.9947 - val_accuracy: 0.4569 - val_loss: 1.4920 - learning_rate: 1.0000e-04\n",
            "Epoch 83/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3059 - loss: 1.8877 - val_accuracy: 0.4741 - val_loss: 1.4891 - learning_rate: 1.0000e-04\n",
            "Epoch 84/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3109 - loss: 1.8891 - val_accuracy: 0.4828 - val_loss: 1.4848 - learning_rate: 1.0000e-04\n",
            "Epoch 85/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3057 - loss: 1.8529 - val_accuracy: 0.4914 - val_loss: 1.4830 - learning_rate: 1.0000e-04\n",
            "Epoch 86/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3234 - loss: 1.8453 - val_accuracy: 0.4741 - val_loss: 1.4810 - learning_rate: 1.0000e-04\n",
            "Epoch 87/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3090 - loss: 1.8549 - val_accuracy: 0.4741 - val_loss: 1.4775 - learning_rate: 1.0000e-04\n",
            "Epoch 88/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3037 - loss: 1.9113 - val_accuracy: 0.4828 - val_loss: 1.4747 - learning_rate: 1.0000e-04\n",
            "Epoch 89/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 1.8506 - val_accuracy: 0.4741 - val_loss: 1.4731 - learning_rate: 1.0000e-04\n",
            "Epoch 90/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3048 - loss: 1.8982 - val_accuracy: 0.4914 - val_loss: 1.4697 - learning_rate: 1.0000e-04\n",
            "Epoch 91/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3159 - loss: 1.8562 - val_accuracy: 0.5086 - val_loss: 1.4653 - learning_rate: 1.0000e-04\n",
            "Epoch 92/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3468 - loss: 1.8342 - val_accuracy: 0.5000 - val_loss: 1.4612 - learning_rate: 1.0000e-04\n",
            "Epoch 93/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3110 - loss: 1.8235 - val_accuracy: 0.5172 - val_loss: 1.4584 - learning_rate: 1.0000e-04\n",
            "Epoch 94/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3541 - loss: 1.7543 - val_accuracy: 0.5000 - val_loss: 1.4577 - learning_rate: 1.0000e-04\n",
            "Epoch 95/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3158 - loss: 1.8746 - val_accuracy: 0.5000 - val_loss: 1.4532 - learning_rate: 1.0000e-04\n",
            "Epoch 96/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3070 - loss: 1.8023 - val_accuracy: 0.5086 - val_loss: 1.4473 - learning_rate: 1.0000e-04\n",
            "Epoch 97/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3469 - loss: 1.7644 - val_accuracy: 0.5172 - val_loss: 1.4468 - learning_rate: 1.0000e-04\n",
            "Epoch 98/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2974 - loss: 1.8474 - val_accuracy: 0.5086 - val_loss: 1.4473 - learning_rate: 1.0000e-04\n",
            "Epoch 99/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 1.7695 - val_accuracy: 0.5000 - val_loss: 1.4477 - learning_rate: 1.0000e-04\n",
            "Epoch 100/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3093 - loss: 1.7854 - val_accuracy: 0.5000 - val_loss: 1.4446 - learning_rate: 1.0000e-04\n",
            "Epoch 101/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3486 - loss: 1.8063 - val_accuracy: 0.5086 - val_loss: 1.4434 - learning_rate: 1.0000e-04\n",
            "Epoch 102/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3236 - loss: 1.8336 - val_accuracy: 0.5000 - val_loss: 1.4429 - learning_rate: 1.0000e-04\n",
            "Epoch 103/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3261 - loss: 1.7886 - val_accuracy: 0.5086 - val_loss: 1.4381 - learning_rate: 1.0000e-04\n",
            "Epoch 104/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3610 - loss: 1.7762 - val_accuracy: 0.5086 - val_loss: 1.4329 - learning_rate: 1.0000e-04\n",
            "Epoch 105/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3352 - loss: 1.8262 - val_accuracy: 0.5000 - val_loss: 1.4317 - learning_rate: 1.0000e-04\n",
            "Epoch 106/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3591 - loss: 1.6780 - val_accuracy: 0.5000 - val_loss: 1.4262 - learning_rate: 1.0000e-04\n",
            "Epoch 107/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3130 - loss: 1.7959 - val_accuracy: 0.5086 - val_loss: 1.4220 - learning_rate: 1.0000e-04\n",
            "Epoch 108/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3650 - loss: 1.7554 - val_accuracy: 0.5086 - val_loss: 1.4202 - learning_rate: 1.0000e-04\n",
            "Epoch 109/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3623 - loss: 1.7043 - val_accuracy: 0.5259 - val_loss: 1.4172 - learning_rate: 1.0000e-04\n",
            "Epoch 110/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3465 - loss: 1.7889 - val_accuracy: 0.5345 - val_loss: 1.4178 - learning_rate: 1.0000e-04\n",
            "Epoch 111/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3447 - loss: 1.7931 - val_accuracy: 0.5259 - val_loss: 1.4164 - learning_rate: 1.0000e-04\n",
            "Epoch 112/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 1.6682 - val_accuracy: 0.5345 - val_loss: 1.4132 - learning_rate: 1.0000e-04\n",
            "Epoch 113/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3626 - loss: 1.7404 - val_accuracy: 0.5431 - val_loss: 1.4104 - learning_rate: 1.0000e-04\n",
            "Epoch 114/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3528 - loss: 1.7307 - val_accuracy: 0.5259 - val_loss: 1.4085 - learning_rate: 1.0000e-04\n",
            "Epoch 115/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3615 - loss: 1.7326 - val_accuracy: 0.5172 - val_loss: 1.4032 - learning_rate: 1.0000e-04\n",
            "Epoch 116/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3541 - loss: 1.8097 - val_accuracy: 0.5345 - val_loss: 1.3979 - learning_rate: 1.0000e-04\n",
            "Epoch 117/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3806 - loss: 1.6797 - val_accuracy: 0.5259 - val_loss: 1.3937 - learning_rate: 1.0000e-04\n",
            "Epoch 118/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3458 - loss: 1.7176 - val_accuracy: 0.5345 - val_loss: 1.3914 - learning_rate: 1.0000e-04\n",
            "Epoch 119/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3570 - loss: 1.7375 - val_accuracy: 0.5431 - val_loss: 1.3902 - learning_rate: 1.0000e-04\n",
            "Epoch 120/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3688 - loss: 1.7368 - val_accuracy: 0.5431 - val_loss: 1.3883 - learning_rate: 1.0000e-04\n",
            "Epoch 121/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3285 - loss: 1.7365 - val_accuracy: 0.5259 - val_loss: 1.3850 - learning_rate: 1.0000e-04\n",
            "Epoch 122/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3746 - loss: 1.6896 - val_accuracy: 0.5259 - val_loss: 1.3839 - learning_rate: 1.0000e-04\n",
            "Epoch 123/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3829 - loss: 1.6714 - val_accuracy: 0.5345 - val_loss: 1.3833 - learning_rate: 1.0000e-04\n",
            "Epoch 124/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3957 - loss: 1.6877 - val_accuracy: 0.5259 - val_loss: 1.3810 - learning_rate: 1.0000e-04\n",
            "Epoch 125/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3728 - loss: 1.6692 - val_accuracy: 0.5431 - val_loss: 1.3781 - learning_rate: 1.0000e-04\n",
            "Epoch 126/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3921 - loss: 1.6564 - val_accuracy: 0.5431 - val_loss: 1.3768 - learning_rate: 1.0000e-04\n",
            "Epoch 127/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3653 - loss: 1.6862 - val_accuracy: 0.5259 - val_loss: 1.3769 - learning_rate: 1.0000e-04\n",
            "Epoch 128/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3786 - loss: 1.6794 - val_accuracy: 0.5431 - val_loss: 1.3701 - learning_rate: 1.0000e-04\n",
            "Epoch 129/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3664 - loss: 1.6396 - val_accuracy: 0.5431 - val_loss: 1.3670 - learning_rate: 1.0000e-04\n",
            "Epoch 130/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3803 - loss: 1.6915 - val_accuracy: 0.5603 - val_loss: 1.3618 - learning_rate: 1.0000e-04\n",
            "Epoch 131/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3651 - loss: 1.7168 - val_accuracy: 0.5690 - val_loss: 1.3595 - learning_rate: 1.0000e-04\n",
            "Epoch 132/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4083 - loss: 1.6244 - val_accuracy: 0.5690 - val_loss: 1.3573 - learning_rate: 1.0000e-04\n",
            "Epoch 133/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3505 - loss: 1.7261 - val_accuracy: 0.5776 - val_loss: 1.3545 - learning_rate: 1.0000e-04\n",
            "Epoch 134/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3902 - loss: 1.6424 - val_accuracy: 0.5776 - val_loss: 1.3528 - learning_rate: 1.0000e-04\n",
            "Epoch 135/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4066 - loss: 1.6297 - val_accuracy: 0.5776 - val_loss: 1.3499 - learning_rate: 1.0000e-04\n",
            "Epoch 136/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3740 - loss: 1.6931 - val_accuracy: 0.5862 - val_loss: 1.3472 - learning_rate: 1.0000e-04\n",
            "Epoch 137/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3777 - loss: 1.6547 - val_accuracy: 0.5690 - val_loss: 1.3437 - learning_rate: 1.0000e-04\n",
            "Epoch 138/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4072 - loss: 1.6058 - val_accuracy: 0.5603 - val_loss: 1.3403 - learning_rate: 1.0000e-04\n",
            "Epoch 139/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4170 - loss: 1.5602 - val_accuracy: 0.5862 - val_loss: 1.3423 - learning_rate: 1.0000e-04\n",
            "Epoch 140/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4138 - loss: 1.6076 - val_accuracy: 0.5776 - val_loss: 1.3414 - learning_rate: 1.0000e-04\n",
            "Epoch 141/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3594 - loss: 1.6802 - val_accuracy: 0.5690 - val_loss: 1.3361 - learning_rate: 1.0000e-04\n",
            "Epoch 142/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3988 - loss: 1.6359 - val_accuracy: 0.5690 - val_loss: 1.3341 - learning_rate: 1.0000e-04\n",
            "Epoch 143/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4073 - loss: 1.5759 - val_accuracy: 0.5690 - val_loss: 1.3298 - learning_rate: 1.0000e-04\n",
            "Epoch 144/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3952 - loss: 1.6154 - val_accuracy: 0.5690 - val_loss: 1.3295 - learning_rate: 1.0000e-04\n",
            "Epoch 145/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3830 - loss: 1.6095 - val_accuracy: 0.5690 - val_loss: 1.3276 - learning_rate: 1.0000e-04\n",
            "Epoch 146/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3671 - loss: 1.6220 - val_accuracy: 0.5603 - val_loss: 1.3231 - learning_rate: 1.0000e-04\n",
            "Epoch 147/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4199 - loss: 1.6002 - val_accuracy: 0.5776 - val_loss: 1.3223 - learning_rate: 1.0000e-04\n",
            "Epoch 148/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4116 - loss: 1.6086 - val_accuracy: 0.5862 - val_loss: 1.3205 - learning_rate: 1.0000e-04\n",
            "Epoch 149/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4074 - loss: 1.5973 - val_accuracy: 0.5690 - val_loss: 1.3204 - learning_rate: 1.0000e-04\n",
            "Epoch 150/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4175 - loss: 1.5789 - val_accuracy: 0.5776 - val_loss: 1.3172 - learning_rate: 1.0000e-04\n",
            "Epoch 151/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4252 - loss: 1.5226 - val_accuracy: 0.5776 - val_loss: 1.3135 - learning_rate: 1.0000e-04\n",
            "Epoch 152/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3813 - loss: 1.5628 - val_accuracy: 0.5862 - val_loss: 1.3123 - learning_rate: 1.0000e-04\n",
            "Epoch 153/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3986 - loss: 1.5351 - val_accuracy: 0.5776 - val_loss: 1.3093 - learning_rate: 1.0000e-04\n",
            "Epoch 154/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4333 - loss: 1.5316 - val_accuracy: 0.5862 - val_loss: 1.3061 - learning_rate: 1.0000e-04\n",
            "Epoch 155/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4016 - loss: 1.5729 - val_accuracy: 0.6034 - val_loss: 1.3039 - learning_rate: 1.0000e-04\n",
            "Epoch 156/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4480 - loss: 1.5117 - val_accuracy: 0.5776 - val_loss: 1.3018 - learning_rate: 1.0000e-04\n",
            "Epoch 157/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4505 - loss: 1.5176 - val_accuracy: 0.5776 - val_loss: 1.3008 - learning_rate: 1.0000e-04\n",
            "Epoch 158/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3740 - loss: 1.6319 - val_accuracy: 0.5776 - val_loss: 1.2979 - learning_rate: 1.0000e-04\n",
            "Epoch 159/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4018 - loss: 1.6252 - val_accuracy: 0.5776 - val_loss: 1.2969 - learning_rate: 1.0000e-04\n",
            "Epoch 160/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4303 - loss: 1.5396 - val_accuracy: 0.5862 - val_loss: 1.2955 - learning_rate: 1.0000e-04\n",
            "Epoch 161/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3735 - loss: 1.6043 - val_accuracy: 0.5776 - val_loss: 1.2954 - learning_rate: 1.0000e-04\n",
            "Epoch 162/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3935 - loss: 1.5456 - val_accuracy: 0.5948 - val_loss: 1.2901 - learning_rate: 1.0000e-04\n",
            "Epoch 163/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4030 - loss: 1.5605 - val_accuracy: 0.5948 - val_loss: 1.2906 - learning_rate: 1.0000e-04\n",
            "Epoch 164/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3967 - loss: 1.5540 - val_accuracy: 0.6034 - val_loss: 1.2871 - learning_rate: 1.0000e-04\n",
            "Epoch 165/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4284 - loss: 1.5304 - val_accuracy: 0.6034 - val_loss: 1.2838 - learning_rate: 1.0000e-04\n",
            "Epoch 166/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3867 - loss: 1.5836 - val_accuracy: 0.5862 - val_loss: 1.2780 - learning_rate: 1.0000e-04\n",
            "Epoch 167/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4289 - loss: 1.5003 - val_accuracy: 0.5862 - val_loss: 1.2756 - learning_rate: 1.0000e-04\n",
            "Epoch 168/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4581 - loss: 1.4531 - val_accuracy: 0.5862 - val_loss: 1.2731 - learning_rate: 1.0000e-04\n",
            "Epoch 169/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4282 - loss: 1.4848 - val_accuracy: 0.6034 - val_loss: 1.2723 - learning_rate: 1.0000e-04\n",
            "Epoch 170/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4280 - loss: 1.4617 - val_accuracy: 0.6034 - val_loss: 1.2698 - learning_rate: 1.0000e-04\n",
            "Epoch 171/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4478 - loss: 1.4546 - val_accuracy: 0.6034 - val_loss: 1.2660 - learning_rate: 1.0000e-04\n",
            "Epoch 172/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4408 - loss: 1.5236 - val_accuracy: 0.5948 - val_loss: 1.2631 - learning_rate: 1.0000e-04\n",
            "Epoch 173/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4172 - loss: 1.5146 - val_accuracy: 0.5948 - val_loss: 1.2591 - learning_rate: 1.0000e-04\n",
            "Epoch 174/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 1.4377 - val_accuracy: 0.5948 - val_loss: 1.2591 - learning_rate: 1.0000e-04\n",
            "Epoch 175/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4225 - loss: 1.5160 - val_accuracy: 0.6121 - val_loss: 1.2599 - learning_rate: 1.0000e-04\n",
            "Epoch 176/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4635 - loss: 1.5081 - val_accuracy: 0.6121 - val_loss: 1.2556 - learning_rate: 1.0000e-04\n",
            "Epoch 177/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4217 - loss: 1.5329 - val_accuracy: 0.6034 - val_loss: 1.2545 - learning_rate: 1.0000e-04\n",
            "Epoch 178/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4366 - loss: 1.4476 - val_accuracy: 0.6034 - val_loss: 1.2501 - learning_rate: 1.0000e-04\n",
            "Epoch 179/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4433 - loss: 1.5091 - val_accuracy: 0.5948 - val_loss: 1.2466 - learning_rate: 1.0000e-04\n",
            "Epoch 180/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4490 - loss: 1.4769 - val_accuracy: 0.6034 - val_loss: 1.2472 - learning_rate: 1.0000e-04\n",
            "Epoch 181/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4710 - loss: 1.4435 - val_accuracy: 0.6121 - val_loss: 1.2415 - learning_rate: 1.0000e-04\n",
            "Epoch 182/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4871 - loss: 1.4317 - val_accuracy: 0.6121 - val_loss: 1.2396 - learning_rate: 1.0000e-04\n",
            "Epoch 183/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4568 - loss: 1.4846 - val_accuracy: 0.6293 - val_loss: 1.2365 - learning_rate: 1.0000e-04\n",
            "Epoch 184/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4494 - loss: 1.4662 - val_accuracy: 0.6207 - val_loss: 1.2322 - learning_rate: 1.0000e-04\n",
            "Epoch 185/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4559 - loss: 1.4449 - val_accuracy: 0.6121 - val_loss: 1.2293 - learning_rate: 1.0000e-04\n",
            "Epoch 186/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4396 - loss: 1.5132 - val_accuracy: 0.6034 - val_loss: 1.2251 - learning_rate: 1.0000e-04\n",
            "Epoch 187/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4535 - loss: 1.4187 - val_accuracy: 0.5776 - val_loss: 1.2221 - learning_rate: 1.0000e-04\n",
            "Epoch 188/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4494 - loss: 1.4738 - val_accuracy: 0.5776 - val_loss: 1.2221 - learning_rate: 1.0000e-04\n",
            "Epoch 189/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4577 - loss: 1.3980 - val_accuracy: 0.5862 - val_loss: 1.2222 - learning_rate: 1.0000e-04\n",
            "Epoch 190/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4721 - loss: 1.3940 - val_accuracy: 0.5948 - val_loss: 1.2231 - learning_rate: 1.0000e-04\n",
            "Epoch 191/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4388 - loss: 1.4750 - val_accuracy: 0.6121 - val_loss: 1.2197 - learning_rate: 1.0000e-04\n",
            "Epoch 192/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4488 - loss: 1.4794 - val_accuracy: 0.6034 - val_loss: 1.2177 - learning_rate: 1.0000e-04\n",
            "Epoch 193/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4352 - loss: 1.5265 - val_accuracy: 0.5948 - val_loss: 1.2169 - learning_rate: 1.0000e-04\n",
            "Epoch 194/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4522 - loss: 1.4152 - val_accuracy: 0.5948 - val_loss: 1.2164 - learning_rate: 1.0000e-04\n",
            "Epoch 195/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4664 - loss: 1.4558 - val_accuracy: 0.5948 - val_loss: 1.2171 - learning_rate: 1.0000e-04\n",
            "Epoch 196/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4689 - loss: 1.3518 - val_accuracy: 0.5862 - val_loss: 1.2173 - learning_rate: 1.0000e-04\n",
            "Epoch 197/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4728 - loss: 1.4203 - val_accuracy: 0.5948 - val_loss: 1.2111 - learning_rate: 1.0000e-04\n",
            "Epoch 198/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4255 - loss: 1.4325 - val_accuracy: 0.6121 - val_loss: 1.2093 - learning_rate: 1.0000e-04\n",
            "Epoch 199/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4812 - loss: 1.3743 - val_accuracy: 0.6121 - val_loss: 1.2049 - learning_rate: 1.0000e-04\n",
            "Epoch 200/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4788 - loss: 1.4300 - val_accuracy: 0.6293 - val_loss: 1.2026 - learning_rate: 1.0000e-04\n",
            "Epoch 201/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 1.4175 - val_accuracy: 0.6379 - val_loss: 1.2031 - learning_rate: 1.0000e-04\n",
            "Epoch 202/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5087 - loss: 1.3389 - val_accuracy: 0.6034 - val_loss: 1.1971 - learning_rate: 1.0000e-04\n",
            "Epoch 203/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4596 - loss: 1.4124 - val_accuracy: 0.6121 - val_loss: 1.1945 - learning_rate: 1.0000e-04\n",
            "Epoch 204/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4643 - loss: 1.4370 - val_accuracy: 0.6121 - val_loss: 1.1941 - learning_rate: 1.0000e-04\n",
            "Epoch 205/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4685 - loss: 1.3867 - val_accuracy: 0.6034 - val_loss: 1.1944 - learning_rate: 1.0000e-04\n",
            "Epoch 206/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4529 - loss: 1.4370 - val_accuracy: 0.5862 - val_loss: 1.1943 - learning_rate: 1.0000e-04\n",
            "Epoch 207/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4543 - loss: 1.4409 - val_accuracy: 0.5948 - val_loss: 1.1905 - learning_rate: 1.0000e-04\n",
            "Epoch 208/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5083 - loss: 1.4164 - val_accuracy: 0.5948 - val_loss: 1.1905 - learning_rate: 1.0000e-04\n",
            "Epoch 209/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4274 - loss: 1.4742 - val_accuracy: 0.6121 - val_loss: 1.1878 - learning_rate: 1.0000e-04\n",
            "Epoch 210/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4699 - loss: 1.3775 - val_accuracy: 0.6034 - val_loss: 1.1870 - learning_rate: 1.0000e-04\n",
            "Epoch 211/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4749 - loss: 1.4028 - val_accuracy: 0.6207 - val_loss: 1.1823 - learning_rate: 1.0000e-04\n",
            "Epoch 212/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4685 - loss: 1.3835 - val_accuracy: 0.6207 - val_loss: 1.1822 - learning_rate: 1.0000e-04\n",
            "Epoch 213/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4897 - loss: 1.3514 - val_accuracy: 0.6121 - val_loss: 1.1798 - learning_rate: 1.0000e-04\n",
            "Epoch 214/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4683 - loss: 1.4272 - val_accuracy: 0.6034 - val_loss: 1.1754 - learning_rate: 1.0000e-04\n",
            "Epoch 215/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4853 - loss: 1.3739 - val_accuracy: 0.6121 - val_loss: 1.1721 - learning_rate: 1.0000e-04\n",
            "Epoch 216/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5002 - loss: 1.3425 - val_accuracy: 0.6207 - val_loss: 1.1711 - learning_rate: 1.0000e-04\n",
            "Epoch 217/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5018 - loss: 1.3857 - val_accuracy: 0.6207 - val_loss: 1.1748 - learning_rate: 1.0000e-04\n",
            "Epoch 218/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5253 - loss: 1.3230 - val_accuracy: 0.6379 - val_loss: 1.1716 - learning_rate: 1.0000e-04\n",
            "Epoch 219/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4627 - loss: 1.3575 - val_accuracy: 0.6293 - val_loss: 1.1736 - learning_rate: 1.0000e-04\n",
            "Epoch 220/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5129 - loss: 1.3359 - val_accuracy: 0.6293 - val_loss: 1.1689 - learning_rate: 1.0000e-04\n",
            "Epoch 221/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4811 - loss: 1.4063 - val_accuracy: 0.6379 - val_loss: 1.1637 - learning_rate: 1.0000e-04\n",
            "Epoch 222/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4680 - loss: 1.3617 - val_accuracy: 0.6207 - val_loss: 1.1606 - learning_rate: 1.0000e-04\n",
            "Epoch 223/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5089 - loss: 1.3173 - val_accuracy: 0.6207 - val_loss: 1.1604 - learning_rate: 1.0000e-04\n",
            "Epoch 224/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4871 - loss: 1.4053 - val_accuracy: 0.6379 - val_loss: 1.1597 - learning_rate: 1.0000e-04\n",
            "Epoch 225/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4752 - loss: 1.3643 - val_accuracy: 0.6207 - val_loss: 1.1597 - learning_rate: 1.0000e-04\n",
            "Epoch 226/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 1.3511 - val_accuracy: 0.6293 - val_loss: 1.1590 - learning_rate: 1.0000e-04\n",
            "Epoch 227/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4904 - loss: 1.3304 - val_accuracy: 0.6379 - val_loss: 1.1546 - learning_rate: 1.0000e-04\n",
            "Epoch 228/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4730 - loss: 1.3797 - val_accuracy: 0.6466 - val_loss: 1.1498 - learning_rate: 1.0000e-04\n",
            "Epoch 229/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5020 - loss: 1.3344 - val_accuracy: 0.6466 - val_loss: 1.1471 - learning_rate: 1.0000e-04\n",
            "Epoch 230/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4884 - loss: 1.3544 - val_accuracy: 0.6293 - val_loss: 1.1464 - learning_rate: 1.0000e-04\n",
            "Epoch 231/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4922 - loss: 1.3164 - val_accuracy: 0.6293 - val_loss: 1.1414 - learning_rate: 1.0000e-04\n",
            "Epoch 232/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5004 - loss: 1.3163 - val_accuracy: 0.6293 - val_loss: 1.1413 - learning_rate: 1.0000e-04\n",
            "Epoch 233/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5005 - loss: 1.3501 - val_accuracy: 0.6293 - val_loss: 1.1424 - learning_rate: 1.0000e-04\n",
            "Epoch 234/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4912 - loss: 1.3774 - val_accuracy: 0.6293 - val_loss: 1.1417 - learning_rate: 1.0000e-04\n",
            "Epoch 235/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4883 - loss: 1.3109 - val_accuracy: 0.6207 - val_loss: 1.1367 - learning_rate: 1.0000e-04\n",
            "Epoch 236/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5552 - loss: 1.2481 - val_accuracy: 0.6379 - val_loss: 1.1330 - learning_rate: 1.0000e-04\n",
            "Epoch 237/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5004 - loss: 1.3465 - val_accuracy: 0.6552 - val_loss: 1.1330 - learning_rate: 1.0000e-04\n",
            "Epoch 238/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5009 - loss: 1.3308 - val_accuracy: 0.6466 - val_loss: 1.1301 - learning_rate: 1.0000e-04\n",
            "Epoch 239/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5368 - loss: 1.2749 - val_accuracy: 0.6379 - val_loss: 1.1280 - learning_rate: 1.0000e-04\n",
            "Epoch 240/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5428 - loss: 1.2268 - val_accuracy: 0.6379 - val_loss: 1.1248 - learning_rate: 1.0000e-04\n",
            "Epoch 241/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5129 - loss: 1.3469 - val_accuracy: 0.6379 - val_loss: 1.1228 - learning_rate: 1.0000e-04\n",
            "Epoch 242/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4878 - loss: 1.3723 - val_accuracy: 0.6379 - val_loss: 1.1218 - learning_rate: 1.0000e-04\n",
            "Epoch 243/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 1.2815 - val_accuracy: 0.6379 - val_loss: 1.1205 - learning_rate: 1.0000e-04\n",
            "Epoch 244/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4888 - loss: 1.3258 - val_accuracy: 0.6379 - val_loss: 1.1208 - learning_rate: 1.0000e-04\n",
            "Epoch 245/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5365 - loss: 1.3253 - val_accuracy: 0.6379 - val_loss: 1.1230 - learning_rate: 1.0000e-04\n",
            "Epoch 246/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5309 - loss: 1.2790 - val_accuracy: 0.6379 - val_loss: 1.1196 - learning_rate: 1.0000e-04\n",
            "Epoch 247/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4983 - loss: 1.3291 - val_accuracy: 0.6293 - val_loss: 1.1145 - learning_rate: 1.0000e-04\n",
            "Epoch 248/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4995 - loss: 1.3372 - val_accuracy: 0.6121 - val_loss: 1.1135 - learning_rate: 1.0000e-04\n",
            "Epoch 249/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5032 - loss: 1.3223 - val_accuracy: 0.6121 - val_loss: 1.1123 - learning_rate: 1.0000e-04\n",
            "Epoch 250/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5251 - loss: 1.2738 - val_accuracy: 0.6121 - val_loss: 1.1106 - learning_rate: 1.0000e-04\n",
            "Epoch 251/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5122 - loss: 1.2404 - val_accuracy: 0.6207 - val_loss: 1.1123 - learning_rate: 1.0000e-04\n",
            "Epoch 252/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5357 - loss: 1.2351 - val_accuracy: 0.6207 - val_loss: 1.1100 - learning_rate: 1.0000e-04\n",
            "Epoch 253/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 1.2859 - val_accuracy: 0.6207 - val_loss: 1.1042 - learning_rate: 1.0000e-04\n",
            "Epoch 254/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5281 - loss: 1.2595 - val_accuracy: 0.6293 - val_loss: 1.1036 - learning_rate: 1.0000e-04\n",
            "Epoch 255/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5193 - loss: 1.2451 - val_accuracy: 0.6293 - val_loss: 1.0994 - learning_rate: 1.0000e-04\n",
            "Epoch 256/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5457 - loss: 1.3058 - val_accuracy: 0.6293 - val_loss: 1.1007 - learning_rate: 1.0000e-04\n",
            "Epoch 257/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5116 - loss: 1.2732 - val_accuracy: 0.6121 - val_loss: 1.0970 - learning_rate: 1.0000e-04\n",
            "Epoch 258/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5408 - loss: 1.2577 - val_accuracy: 0.6207 - val_loss: 1.0943 - learning_rate: 1.0000e-04\n",
            "Epoch 259/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5150 - loss: 1.2556 - val_accuracy: 0.6379 - val_loss: 1.0963 - learning_rate: 1.0000e-04\n",
            "Epoch 260/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5196 - loss: 1.2965 - val_accuracy: 0.6293 - val_loss: 1.0954 - learning_rate: 1.0000e-04\n",
            "Epoch 261/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5386 - loss: 1.2755 - val_accuracy: 0.6207 - val_loss: 1.0929 - learning_rate: 1.0000e-04\n",
            "Epoch 262/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4911 - loss: 1.3266 - val_accuracy: 0.6207 - val_loss: 1.0921 - learning_rate: 1.0000e-04\n",
            "Epoch 263/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5536 - loss: 1.2132 - val_accuracy: 0.6293 - val_loss: 1.0924 - learning_rate: 1.0000e-04\n",
            "Epoch 264/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5466 - loss: 1.2217 - val_accuracy: 0.6293 - val_loss: 1.0909 - learning_rate: 1.0000e-04\n",
            "Epoch 265/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: 1.2703 - val_accuracy: 0.6293 - val_loss: 1.0944 - learning_rate: 1.0000e-04\n",
            "Epoch 266/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5193 - loss: 1.2671 - val_accuracy: 0.6293 - val_loss: 1.0894 - learning_rate: 1.0000e-04\n",
            "Epoch 267/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5457 - loss: 1.2245 - val_accuracy: 0.6379 - val_loss: 1.0895 - learning_rate: 1.0000e-04\n",
            "Epoch 268/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5291 - loss: 1.2215 - val_accuracy: 0.6207 - val_loss: 1.0904 - learning_rate: 1.0000e-04\n",
            "Epoch 269/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.2661 - val_accuracy: 0.6293 - val_loss: 1.0891 - learning_rate: 1.0000e-04\n",
            "Epoch 270/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5704 - loss: 1.1995 - val_accuracy: 0.6379 - val_loss: 1.0839 - learning_rate: 1.0000e-04\n",
            "Epoch 271/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 1.2463 - val_accuracy: 0.6466 - val_loss: 1.0799 - learning_rate: 1.0000e-04\n",
            "Epoch 272/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 1.1962 - val_accuracy: 0.6379 - val_loss: 1.0769 - learning_rate: 1.0000e-04\n",
            "Epoch 273/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5210 - loss: 1.3100 - val_accuracy: 0.6466 - val_loss: 1.0757 - learning_rate: 1.0000e-04\n",
            "Epoch 274/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5440 - loss: 1.2531 - val_accuracy: 0.6552 - val_loss: 1.0766 - learning_rate: 1.0000e-04\n",
            "Epoch 275/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5491 - loss: 1.2208 - val_accuracy: 0.6638 - val_loss: 1.0725 - learning_rate: 1.0000e-04\n",
            "Epoch 276/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5541 - loss: 1.2157 - val_accuracy: 0.6466 - val_loss: 1.0715 - learning_rate: 1.0000e-04\n",
            "Epoch 277/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5541 - loss: 1.2342 - val_accuracy: 0.6466 - val_loss: 1.0718 - learning_rate: 1.0000e-04\n",
            "Epoch 278/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 1.2147 - val_accuracy: 0.6379 - val_loss: 1.0720 - learning_rate: 1.0000e-04\n",
            "Epoch 279/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5768 - loss: 1.1942 - val_accuracy: 0.6379 - val_loss: 1.0690 - learning_rate: 1.0000e-04\n",
            "Epoch 280/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5541 - loss: 1.2278 - val_accuracy: 0.6293 - val_loss: 1.0675 - learning_rate: 1.0000e-04\n",
            "Epoch 281/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5398 - loss: 1.2431 - val_accuracy: 0.6293 - val_loss: 1.0668 - learning_rate: 1.0000e-04\n",
            "Epoch 282/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5507 - loss: 1.2041 - val_accuracy: 0.6293 - val_loss: 1.0637 - learning_rate: 1.0000e-04\n",
            "Epoch 283/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 1.1587 - val_accuracy: 0.6379 - val_loss: 1.0619 - learning_rate: 1.0000e-04\n",
            "Epoch 284/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5486 - loss: 1.2057 - val_accuracy: 0.6379 - val_loss: 1.0613 - learning_rate: 1.0000e-04\n",
            "Epoch 285/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5497 - loss: 1.2189 - val_accuracy: 0.6466 - val_loss: 1.0582 - learning_rate: 1.0000e-04\n",
            "Epoch 286/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5449 - loss: 1.2138 - val_accuracy: 0.6466 - val_loss: 1.0573 - learning_rate: 1.0000e-04\n",
            "Epoch 287/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5645 - loss: 1.2013 - val_accuracy: 0.6466 - val_loss: 1.0558 - learning_rate: 1.0000e-04\n",
            "Epoch 288/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5479 - loss: 1.2356 - val_accuracy: 0.6379 - val_loss: 1.0554 - learning_rate: 1.0000e-04\n",
            "Epoch 289/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5501 - loss: 1.2084 - val_accuracy: 0.6379 - val_loss: 1.0550 - learning_rate: 1.0000e-04\n",
            "Epoch 290/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5573 - loss: 1.1805 - val_accuracy: 0.6379 - val_loss: 1.0564 - learning_rate: 1.0000e-04\n",
            "Epoch 291/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5714 - loss: 1.1882 - val_accuracy: 0.6552 - val_loss: 1.0567 - learning_rate: 1.0000e-04\n",
            "Epoch 292/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5300 - loss: 1.2499 - val_accuracy: 0.6552 - val_loss: 1.0515 - learning_rate: 1.0000e-04\n",
            "Epoch 293/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5760 - loss: 1.1404 - val_accuracy: 0.6379 - val_loss: 1.0540 - learning_rate: 1.0000e-04\n",
            "Epoch 294/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5313 - loss: 1.2362 - val_accuracy: 0.6379 - val_loss: 1.0523 - learning_rate: 1.0000e-04\n",
            "Epoch 295/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5306 - loss: 1.2584 - val_accuracy: 0.6466 - val_loss: 1.0516 - learning_rate: 1.0000e-04\n",
            "Epoch 296/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5562 - loss: 1.2312 - val_accuracy: 0.6379 - val_loss: 1.0469 - learning_rate: 1.0000e-04\n",
            "Epoch 297/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5424 - loss: 1.2033 - val_accuracy: 0.6466 - val_loss: 1.0442 - learning_rate: 1.0000e-04\n",
            "Epoch 298/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5624 - loss: 1.1715 - val_accuracy: 0.6379 - val_loss: 1.0430 - learning_rate: 1.0000e-04\n",
            "Epoch 299/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 1.2088 - val_accuracy: 0.6552 - val_loss: 1.0410 - learning_rate: 1.0000e-04\n",
            "Epoch 300/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5646 - loss: 1.1996 - val_accuracy: 0.6466 - val_loss: 1.0406 - learning_rate: 1.0000e-04\n",
            "Epoch 301/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6004 - loss: 1.1336 - val_accuracy: 0.6638 - val_loss: 1.0414 - learning_rate: 1.0000e-04\n",
            "Epoch 302/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5746 - loss: 1.1607 - val_accuracy: 0.6638 - val_loss: 1.0404 - learning_rate: 1.0000e-04\n",
            "Epoch 303/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5827 - loss: 1.1754 - val_accuracy: 0.6466 - val_loss: 1.0388 - learning_rate: 1.0000e-04\n",
            "Epoch 304/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5774 - loss: 1.1022 - val_accuracy: 0.6466 - val_loss: 1.0347 - learning_rate: 1.0000e-04\n",
            "Epoch 305/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5412 - loss: 1.1623 - val_accuracy: 0.6466 - val_loss: 1.0318 - learning_rate: 1.0000e-04\n",
            "Epoch 306/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5876 - loss: 1.1921 - val_accuracy: 0.6293 - val_loss: 1.0271 - learning_rate: 1.0000e-04\n",
            "Epoch 307/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5825 - loss: 1.1489 - val_accuracy: 0.6379 - val_loss: 1.0290 - learning_rate: 1.0000e-04\n",
            "Epoch 308/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5777 - loss: 1.1744 - val_accuracy: 0.6466 - val_loss: 1.0283 - learning_rate: 1.0000e-04\n",
            "Epoch 309/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5793 - loss: 1.1792 - val_accuracy: 0.6293 - val_loss: 1.0296 - learning_rate: 1.0000e-04\n",
            "Epoch 310/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5994 - loss: 1.1311 - val_accuracy: 0.6466 - val_loss: 1.0241 - learning_rate: 1.0000e-04\n",
            "Epoch 311/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5867 - loss: 1.1294 - val_accuracy: 0.6552 - val_loss: 1.0201 - learning_rate: 1.0000e-04\n",
            "Epoch 312/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5495 - loss: 1.1562 - val_accuracy: 0.6379 - val_loss: 1.0166 - learning_rate: 1.0000e-04\n",
            "Epoch 313/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5900 - loss: 1.1574 - val_accuracy: 0.6293 - val_loss: 1.0192 - learning_rate: 1.0000e-04\n",
            "Epoch 314/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 1.0910 - val_accuracy: 0.6379 - val_loss: 1.0180 - learning_rate: 1.0000e-04\n",
            "Epoch 315/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5706 - loss: 1.1356 - val_accuracy: 0.6466 - val_loss: 1.0176 - learning_rate: 1.0000e-04\n",
            "Epoch 316/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5789 - loss: 1.1927 - val_accuracy: 0.6466 - val_loss: 1.0164 - learning_rate: 1.0000e-04\n",
            "Epoch 317/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5724 - loss: 1.2128 - val_accuracy: 0.6466 - val_loss: 1.0164 - learning_rate: 1.0000e-04\n",
            "Epoch 318/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5520 - loss: 1.1524 - val_accuracy: 0.6552 - val_loss: 1.0163 - learning_rate: 1.0000e-04\n",
            "Epoch 319/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5953 - loss: 1.1177 - val_accuracy: 0.6466 - val_loss: 1.0182 - learning_rate: 1.0000e-04\n",
            "Epoch 320/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5536 - loss: 1.1925 - val_accuracy: 0.6466 - val_loss: 1.0160 - learning_rate: 1.0000e-04\n",
            "Epoch 321/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5518 - loss: 1.1454 - val_accuracy: 0.6379 - val_loss: 1.0158 - learning_rate: 1.0000e-04\n",
            "Epoch 322/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5926 - loss: 1.1420 - val_accuracy: 0.6466 - val_loss: 1.0170 - learning_rate: 1.0000e-04\n",
            "Epoch 323/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 1.1062 - val_accuracy: 0.6466 - val_loss: 1.0160 - learning_rate: 1.0000e-04\n",
            "Epoch 324/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5758 - loss: 1.1714 - val_accuracy: 0.6552 - val_loss: 1.0158 - learning_rate: 1.0000e-04\n",
            "Epoch 325/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5498 - loss: 1.2071 - val_accuracy: 0.6552 - val_loss: 1.0121 - learning_rate: 1.0000e-04\n",
            "Epoch 326/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5822 - loss: 1.1408 - val_accuracy: 0.6379 - val_loss: 1.0111 - learning_rate: 1.0000e-04\n",
            "Epoch 327/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5736 - loss: 1.1613 - val_accuracy: 0.6466 - val_loss: 1.0090 - learning_rate: 1.0000e-04\n",
            "Epoch 328/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 1.1078 - val_accuracy: 0.6466 - val_loss: 1.0071 - learning_rate: 1.0000e-04\n",
            "Epoch 329/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5877 - loss: 1.1125 - val_accuracy: 0.6552 - val_loss: 1.0112 - learning_rate: 1.0000e-04\n",
            "Epoch 330/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6239 - loss: 1.0556 - val_accuracy: 0.6379 - val_loss: 1.0108 - learning_rate: 1.0000e-04\n",
            "Epoch 331/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6116 - loss: 1.0778 - val_accuracy: 0.6293 - val_loss: 1.0083 - learning_rate: 1.0000e-04\n",
            "Epoch 332/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5932 - loss: 1.0838 - val_accuracy: 0.6293 - val_loss: 1.0048 - learning_rate: 1.0000e-04\n",
            "Epoch 333/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6062 - loss: 1.1275 - val_accuracy: 0.6466 - val_loss: 0.9994 - learning_rate: 1.0000e-04\n",
            "Epoch 334/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5484 - loss: 1.1478 - val_accuracy: 0.6293 - val_loss: 0.9981 - learning_rate: 1.0000e-04\n",
            "Epoch 335/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5771 - loss: 1.1254 - val_accuracy: 0.6207 - val_loss: 0.9914 - learning_rate: 1.0000e-04\n",
            "Epoch 336/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6272 - loss: 1.0370 - val_accuracy: 0.6379 - val_loss: 0.9946 - learning_rate: 1.0000e-04\n",
            "Epoch 337/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5844 - loss: 1.1215 - val_accuracy: 0.6466 - val_loss: 0.9916 - learning_rate: 1.0000e-04\n",
            "Epoch 338/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5806 - loss: 1.0948 - val_accuracy: 0.6466 - val_loss: 0.9894 - learning_rate: 1.0000e-04\n",
            "Epoch 339/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5634 - loss: 1.1815 - val_accuracy: 0.6293 - val_loss: 0.9871 - learning_rate: 1.0000e-04\n",
            "Epoch 340/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.1706 - val_accuracy: 0.6293 - val_loss: 0.9881 - learning_rate: 1.0000e-04\n",
            "Epoch 341/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5660 - loss: 1.1394 - val_accuracy: 0.6293 - val_loss: 0.9886 - learning_rate: 1.0000e-04\n",
            "Epoch 342/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6240 - loss: 1.0508 - val_accuracy: 0.6379 - val_loss: 0.9878 - learning_rate: 1.0000e-04\n",
            "Epoch 343/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5949 - loss: 1.1033 - val_accuracy: 0.6293 - val_loss: 0.9852 - learning_rate: 1.0000e-04\n",
            "Epoch 344/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5750 - loss: 1.1439 - val_accuracy: 0.6379 - val_loss: 0.9867 - learning_rate: 1.0000e-04\n",
            "Epoch 345/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6103 - loss: 1.0571 - val_accuracy: 0.6379 - val_loss: 0.9810 - learning_rate: 1.0000e-04\n",
            "Epoch 346/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5933 - loss: 1.1008 - val_accuracy: 0.6466 - val_loss: 0.9785 - learning_rate: 1.0000e-04\n",
            "Epoch 347/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6045 - loss: 1.1133 - val_accuracy: 0.6121 - val_loss: 0.9785 - learning_rate: 1.0000e-04\n",
            "Epoch 348/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 1.0571 - val_accuracy: 0.6466 - val_loss: 0.9809 - learning_rate: 1.0000e-04\n",
            "Epoch 349/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5742 - loss: 1.1060 - val_accuracy: 0.6466 - val_loss: 0.9821 - learning_rate: 1.0000e-04\n",
            "Epoch 350/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6202 - loss: 1.0727 - val_accuracy: 0.6293 - val_loss: 0.9873 - learning_rate: 1.0000e-04\n",
            "Epoch 351/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6099 - loss: 1.0734 - val_accuracy: 0.6293 - val_loss: 0.9798 - learning_rate: 1.0000e-04\n",
            "Epoch 352/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 1.0603 - val_accuracy: 0.6466 - val_loss: 0.9788 - learning_rate: 1.0000e-04\n",
            "Epoch 353/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 1.1203 - val_accuracy: 0.6466 - val_loss: 0.9769 - learning_rate: 1.0000e-04\n",
            "Epoch 354/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6309 - loss: 1.0266 - val_accuracy: 0.6466 - val_loss: 0.9787 - learning_rate: 1.0000e-04\n",
            "Epoch 355/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.1045 - val_accuracy: 0.6466 - val_loss: 0.9812 - learning_rate: 1.0000e-04\n",
            "Epoch 356/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5675 - loss: 1.1004 - val_accuracy: 0.6466 - val_loss: 0.9810 - learning_rate: 1.0000e-04\n",
            "Epoch 357/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6277 - loss: 1.0580 - val_accuracy: 0.6379 - val_loss: 0.9808 - learning_rate: 1.0000e-04\n",
            "Epoch 358/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5706 - loss: 1.1115 - val_accuracy: 0.6552 - val_loss: 0.9745 - learning_rate: 1.0000e-04\n",
            "Epoch 359/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6279 - loss: 1.0658 - val_accuracy: 0.6466 - val_loss: 0.9667 - learning_rate: 1.0000e-04\n",
            "Epoch 360/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6196 - loss: 1.0374 - val_accuracy: 0.6293 - val_loss: 0.9636 - learning_rate: 1.0000e-04\n",
            "Epoch 361/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6073 - loss: 1.0988 - val_accuracy: 0.6379 - val_loss: 0.9633 - learning_rate: 1.0000e-04\n",
            "Epoch 362/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 1.0291 - val_accuracy: 0.6293 - val_loss: 0.9652 - learning_rate: 1.0000e-04\n",
            "Epoch 363/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6588 - loss: 0.9850 - val_accuracy: 0.6379 - val_loss: 0.9655 - learning_rate: 1.0000e-04\n",
            "Epoch 364/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 1.1198 - val_accuracy: 0.6466 - val_loss: 0.9645 - learning_rate: 1.0000e-04\n",
            "Epoch 365/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 1.0766 - val_accuracy: 0.6466 - val_loss: 0.9662 - learning_rate: 1.0000e-04\n",
            "Epoch 366/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6129 - loss: 1.0381 - val_accuracy: 0.6466 - val_loss: 0.9611 - learning_rate: 1.0000e-04\n",
            "Epoch 367/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6008 - loss: 1.1104 - val_accuracy: 0.6379 - val_loss: 0.9617 - learning_rate: 1.0000e-04\n",
            "Epoch 368/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 1.0859 - val_accuracy: 0.6379 - val_loss: 0.9619 - learning_rate: 1.0000e-04\n",
            "Epoch 369/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6095 - loss: 1.0439 - val_accuracy: 0.6379 - val_loss: 0.9602 - learning_rate: 1.0000e-04\n",
            "Epoch 370/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.9961 - val_accuracy: 0.6379 - val_loss: 0.9591 - learning_rate: 1.0000e-04\n",
            "Epoch 371/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 1.0475 - val_accuracy: 0.6466 - val_loss: 0.9611 - learning_rate: 1.0000e-04\n",
            "Epoch 372/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 1.0474 - val_accuracy: 0.6466 - val_loss: 0.9574 - learning_rate: 1.0000e-04\n",
            "Epoch 373/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6118 - loss: 1.0261 - val_accuracy: 0.6552 - val_loss: 0.9530 - learning_rate: 1.0000e-04\n",
            "Epoch 374/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6174 - loss: 1.0620 - val_accuracy: 0.6552 - val_loss: 0.9535 - learning_rate: 1.0000e-04\n",
            "Epoch 375/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 1.0212 - val_accuracy: 0.6466 - val_loss: 0.9543 - learning_rate: 1.0000e-04\n",
            "Epoch 376/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6401 - loss: 1.0363 - val_accuracy: 0.6466 - val_loss: 0.9521 - learning_rate: 1.0000e-04\n",
            "Epoch 377/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6293 - loss: 1.0323 - val_accuracy: 0.6466 - val_loss: 0.9486 - learning_rate: 1.0000e-04\n",
            "Epoch 378/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6452 - loss: 0.9818 - val_accuracy: 0.6466 - val_loss: 0.9446 - learning_rate: 1.0000e-04\n",
            "Epoch 379/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 1.0453 - val_accuracy: 0.6379 - val_loss: 0.9424 - learning_rate: 1.0000e-04\n",
            "Epoch 380/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5965 - loss: 1.0836 - val_accuracy: 0.6466 - val_loss: 0.9393 - learning_rate: 1.0000e-04\n",
            "Epoch 381/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 1.0405 - val_accuracy: 0.6466 - val_loss: 0.9352 - learning_rate: 1.0000e-04\n",
            "Epoch 382/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6182 - loss: 1.0481 - val_accuracy: 0.6379 - val_loss: 0.9321 - learning_rate: 1.0000e-04\n",
            "Epoch 383/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6096 - loss: 1.0173 - val_accuracy: 0.6552 - val_loss: 0.9302 - learning_rate: 1.0000e-04\n",
            "Epoch 384/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 1.0839 - val_accuracy: 0.6552 - val_loss: 0.9310 - learning_rate: 1.0000e-04\n",
            "Epoch 385/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6374 - loss: 1.0282 - val_accuracy: 0.6379 - val_loss: 0.9318 - learning_rate: 1.0000e-04\n",
            "Epoch 386/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6365 - loss: 1.0216 - val_accuracy: 0.6379 - val_loss: 0.9338 - learning_rate: 1.0000e-04\n",
            "Epoch 387/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 0.9687 - val_accuracy: 0.6466 - val_loss: 0.9310 - learning_rate: 1.0000e-04\n",
            "Epoch 388/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6255 - loss: 1.0151 - val_accuracy: 0.6466 - val_loss: 0.9311 - learning_rate: 1.0000e-04\n",
            "Epoch 389/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6462 - loss: 1.0080 - val_accuracy: 0.6552 - val_loss: 0.9310 - learning_rate: 1.0000e-04\n",
            "Epoch 390/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 1.0383 - val_accuracy: 0.6379 - val_loss: 0.9319 - learning_rate: 1.0000e-04\n",
            "Epoch 391/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6349 - loss: 1.0369 - val_accuracy: 0.6293 - val_loss: 0.9273 - learning_rate: 1.0000e-04\n",
            "Epoch 392/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.9528 - val_accuracy: 0.6379 - val_loss: 0.9258 - learning_rate: 1.0000e-04\n",
            "Epoch 393/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6220 - loss: 1.0466 - val_accuracy: 0.6379 - val_loss: 0.9242 - learning_rate: 1.0000e-04\n",
            "Epoch 394/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6349 - loss: 0.9912 - val_accuracy: 0.6293 - val_loss: 0.9256 - learning_rate: 1.0000e-04\n",
            "Epoch 395/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6019 - loss: 1.1354 - val_accuracy: 0.6466 - val_loss: 0.9248 - learning_rate: 1.0000e-04\n",
            "Epoch 396/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6584 - loss: 0.9453 - val_accuracy: 0.6552 - val_loss: 0.9259 - learning_rate: 1.0000e-04\n",
            "Epoch 397/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6260 - loss: 1.0233 - val_accuracy: 0.6552 - val_loss: 0.9251 - learning_rate: 1.0000e-04\n",
            "Epoch 398/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6166 - loss: 1.0422 - val_accuracy: 0.6552 - val_loss: 0.9208 - learning_rate: 1.0000e-04\n",
            "Epoch 399/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6234 - loss: 0.9737 - val_accuracy: 0.6466 - val_loss: 0.9209 - learning_rate: 1.0000e-04\n",
            "Epoch 400/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6580 - loss: 0.9694 - val_accuracy: 0.6552 - val_loss: 0.9178 - learning_rate: 1.0000e-04\n",
            "Epoch 401/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6463 - loss: 0.9905 - val_accuracy: 0.6466 - val_loss: 0.9172 - learning_rate: 1.0000e-04\n",
            "Epoch 402/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6544 - loss: 0.9772 - val_accuracy: 0.6466 - val_loss: 0.9180 - learning_rate: 1.0000e-04\n",
            "Epoch 403/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6320 - loss: 0.9677 - val_accuracy: 0.6466 - val_loss: 0.9169 - learning_rate: 1.0000e-04\n",
            "Epoch 404/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 0.9572 - val_accuracy: 0.6638 - val_loss: 0.9151 - learning_rate: 1.0000e-04\n",
            "Epoch 405/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 0.9575 - val_accuracy: 0.6638 - val_loss: 0.9134 - learning_rate: 1.0000e-04\n",
            "Epoch 406/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6217 - loss: 0.9886 - val_accuracy: 0.6638 - val_loss: 0.9155 - learning_rate: 1.0000e-04\n",
            "Epoch 407/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 0.9751 - val_accuracy: 0.6466 - val_loss: 0.9184 - learning_rate: 1.0000e-04\n",
            "Epoch 408/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6319 - loss: 0.9969 - val_accuracy: 0.6552 - val_loss: 0.9204 - learning_rate: 1.0000e-04\n",
            "Epoch 409/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6205 - loss: 1.0470 - val_accuracy: 0.6552 - val_loss: 0.9179 - learning_rate: 1.0000e-04\n",
            "Epoch 410/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5981 - loss: 1.0452 - val_accuracy: 0.6466 - val_loss: 0.9200 - learning_rate: 1.0000e-04\n",
            "Epoch 411/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6604 - loss: 0.9054 - val_accuracy: 0.6552 - val_loss: 0.9189 - learning_rate: 1.0000e-04\n",
            "Epoch 412/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.9935 - val_accuracy: 0.6638 - val_loss: 0.9124 - learning_rate: 1.0000e-04\n",
            "Epoch 413/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6696 - loss: 0.9636 - val_accuracy: 0.6552 - val_loss: 0.9098 - learning_rate: 1.0000e-04\n",
            "Epoch 414/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6555 - loss: 0.9500 - val_accuracy: 0.6552 - val_loss: 0.9109 - learning_rate: 1.0000e-04\n",
            "Epoch 415/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6371 - loss: 0.9774 - val_accuracy: 0.6466 - val_loss: 0.9080 - learning_rate: 1.0000e-04\n",
            "Epoch 416/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 0.9695 - val_accuracy: 0.6724 - val_loss: 0.9053 - learning_rate: 1.0000e-04\n",
            "Epoch 417/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6645 - loss: 0.9349 - val_accuracy: 0.6724 - val_loss: 0.9028 - learning_rate: 1.0000e-04\n",
            "Epoch 418/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 0.9600 - val_accuracy: 0.6724 - val_loss: 0.8992 - learning_rate: 1.0000e-04\n",
            "Epoch 419/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6671 - loss: 0.9505 - val_accuracy: 0.6552 - val_loss: 0.9053 - learning_rate: 1.0000e-04\n",
            "Epoch 420/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6431 - loss: 0.9342 - val_accuracy: 0.6552 - val_loss: 0.9028 - learning_rate: 1.0000e-04\n",
            "Epoch 421/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6573 - loss: 0.9757 - val_accuracy: 0.6466 - val_loss: 0.9028 - learning_rate: 1.0000e-04\n",
            "Epoch 422/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6894 - loss: 0.9336 - val_accuracy: 0.6638 - val_loss: 0.8997 - learning_rate: 1.0000e-04\n",
            "Epoch 423/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6533 - loss: 0.9675 - val_accuracy: 0.6897 - val_loss: 0.8995 - learning_rate: 1.0000e-04\n",
            "Epoch 424/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6353 - loss: 0.9769 - val_accuracy: 0.6897 - val_loss: 0.8995 - learning_rate: 1.0000e-04\n",
            "Epoch 425/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6759 - loss: 0.9088 - val_accuracy: 0.6897 - val_loss: 0.8992 - learning_rate: 1.0000e-04\n",
            "Epoch 426/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.9359 - val_accuracy: 0.6897 - val_loss: 0.9012 - learning_rate: 1.0000e-04\n",
            "Epoch 427/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6291 - loss: 0.9777 - val_accuracy: 0.6810 - val_loss: 0.9043 - learning_rate: 1.0000e-04\n",
            "Epoch 428/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6164 - loss: 1.0833 - val_accuracy: 0.6810 - val_loss: 0.8993 - learning_rate: 1.0000e-04\n",
            "Epoch 429/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6706 - loss: 0.9917 - val_accuracy: 0.6897 - val_loss: 0.8986 - learning_rate: 5.0000e-05\n",
            "Epoch 430/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6366 - loss: 0.9811 - val_accuracy: 0.6810 - val_loss: 0.8973 - learning_rate: 5.0000e-05\n",
            "Epoch 431/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6759 - loss: 0.9375 - val_accuracy: 0.6810 - val_loss: 0.8946 - learning_rate: 5.0000e-05\n",
            "Epoch 432/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.8943 - val_accuracy: 0.6810 - val_loss: 0.8938 - learning_rate: 5.0000e-05\n",
            "Epoch 433/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6657 - loss: 0.9215 - val_accuracy: 0.6810 - val_loss: 0.8946 - learning_rate: 5.0000e-05\n",
            "Epoch 434/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 0.9352 - val_accuracy: 0.6810 - val_loss: 0.8942 - learning_rate: 5.0000e-05\n",
            "Epoch 435/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6576 - loss: 0.9592 - val_accuracy: 0.6810 - val_loss: 0.8917 - learning_rate: 5.0000e-05\n",
            "Epoch 436/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6656 - loss: 0.9472 - val_accuracy: 0.6810 - val_loss: 0.8897 - learning_rate: 5.0000e-05\n",
            "Epoch 437/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6256 - loss: 0.9631 - val_accuracy: 0.6810 - val_loss: 0.8893 - learning_rate: 5.0000e-05\n",
            "Epoch 438/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6605 - loss: 0.9494 - val_accuracy: 0.6897 - val_loss: 0.8889 - learning_rate: 5.0000e-05\n",
            "Epoch 439/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6695 - loss: 0.9140 - val_accuracy: 0.6983 - val_loss: 0.8876 - learning_rate: 5.0000e-05\n",
            "Epoch 440/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6857 - loss: 0.9338 - val_accuracy: 0.6724 - val_loss: 0.8901 - learning_rate: 5.0000e-05\n",
            "Epoch 441/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6742 - loss: 0.9189 - val_accuracy: 0.6810 - val_loss: 0.8905 - learning_rate: 5.0000e-05\n",
            "Epoch 442/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6332 - loss: 1.0010 - val_accuracy: 0.6810 - val_loss: 0.8930 - learning_rate: 5.0000e-05\n",
            "Epoch 443/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6273 - loss: 0.9719 - val_accuracy: 0.6810 - val_loss: 0.8907 - learning_rate: 5.0000e-05\n",
            "Epoch 444/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6868 - loss: 0.9057 - val_accuracy: 0.6810 - val_loss: 0.8910 - learning_rate: 5.0000e-05\n",
            "Epoch 445/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6540 - loss: 0.9531 - val_accuracy: 0.6810 - val_loss: 0.8921 - learning_rate: 5.0000e-05\n",
            "Epoch 446/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 0.9274 - val_accuracy: 0.6810 - val_loss: 0.8906 - learning_rate: 5.0000e-05\n",
            "Epoch 447/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 0.9120 - val_accuracy: 0.6810 - val_loss: 0.8909 - learning_rate: 5.0000e-05\n",
            "Epoch 448/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.9633 - val_accuracy: 0.6810 - val_loss: 0.8904 - learning_rate: 5.0000e-05\n",
            "Epoch 449/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6429 - loss: 0.9522 - val_accuracy: 0.6810 - val_loss: 0.8911 - learning_rate: 5.0000e-05\n",
            "Epoch 450/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6808 - loss: 0.9045 - val_accuracy: 0.6810 - val_loss: 0.8911 - learning_rate: 2.5000e-05\n",
            "Epoch 451/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.9145 - val_accuracy: 0.6810 - val_loss: 0.8890 - learning_rate: 2.5000e-05\n",
            "Epoch 452/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6587 - loss: 0.9433 - val_accuracy: 0.6810 - val_loss: 0.8889 - learning_rate: 2.5000e-05\n",
            "Epoch 453/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7038 - loss: 0.8365 - val_accuracy: 0.6897 - val_loss: 0.8871 - learning_rate: 2.5000e-05\n",
            "Epoch 454/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.9103 - val_accuracy: 0.6810 - val_loss: 0.8896 - learning_rate: 2.5000e-05\n",
            "Epoch 455/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6497 - loss: 0.9242 - val_accuracy: 0.6897 - val_loss: 0.8905 - learning_rate: 2.5000e-05\n",
            "Epoch 456/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 0.9810 - val_accuracy: 0.6724 - val_loss: 0.8896 - learning_rate: 2.5000e-05\n",
            "Epoch 457/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6715 - loss: 0.8996 - val_accuracy: 0.6724 - val_loss: 0.8885 - learning_rate: 2.5000e-05\n",
            "Epoch 458/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6685 - loss: 0.9589 - val_accuracy: 0.6724 - val_loss: 0.8872 - learning_rate: 2.5000e-05\n",
            "Epoch 459/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6744 - loss: 0.9039 - val_accuracy: 0.6724 - val_loss: 0.8864 - learning_rate: 2.5000e-05\n",
            "Epoch 460/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6785 - loss: 0.8798 - val_accuracy: 0.6724 - val_loss: 0.8866 - learning_rate: 2.5000e-05\n",
            "Epoch 461/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6577 - loss: 0.9158 - val_accuracy: 0.6724 - val_loss: 0.8847 - learning_rate: 2.5000e-05\n",
            "Epoch 462/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6860 - loss: 0.8489 - val_accuracy: 0.6724 - val_loss: 0.8846 - learning_rate: 2.5000e-05\n",
            "Epoch 463/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6524 - loss: 0.9581 - val_accuracy: 0.6724 - val_loss: 0.8829 - learning_rate: 2.5000e-05\n",
            "Epoch 464/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6734 - loss: 0.9312 - val_accuracy: 0.6724 - val_loss: 0.8817 - learning_rate: 2.5000e-05\n",
            "Epoch 465/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6526 - loss: 0.9489 - val_accuracy: 0.6724 - val_loss: 0.8838 - learning_rate: 2.5000e-05\n",
            "Epoch 466/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6652 - loss: 0.9632 - val_accuracy: 0.6724 - val_loss: 0.8834 - learning_rate: 2.5000e-05\n",
            "Epoch 467/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.9093 - val_accuracy: 0.6724 - val_loss: 0.8822 - learning_rate: 2.5000e-05\n",
            "Epoch 468/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.9068 - val_accuracy: 0.6724 - val_loss: 0.8825 - learning_rate: 2.5000e-05\n",
            "Epoch 469/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6858 - loss: 0.8983 - val_accuracy: 0.6724 - val_loss: 0.8827 - learning_rate: 2.5000e-05\n",
            "Epoch 470/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - loss: 0.9105 - val_accuracy: 0.6724 - val_loss: 0.8823 - learning_rate: 2.5000e-05\n",
            "Epoch 471/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6605 - loss: 0.8926 - val_accuracy: 0.6810 - val_loss: 0.8820 - learning_rate: 2.5000e-05\n",
            "Epoch 472/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6603 - loss: 0.8878 - val_accuracy: 0.6810 - val_loss: 0.8814 - learning_rate: 2.5000e-05\n",
            "Epoch 473/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6621 - loss: 0.9099 - val_accuracy: 0.6897 - val_loss: 0.8818 - learning_rate: 2.5000e-05\n",
            "Epoch 474/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6549 - loss: 0.9460 - val_accuracy: 0.6897 - val_loss: 0.8807 - learning_rate: 2.5000e-05\n",
            "Epoch 475/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6640 - loss: 0.9555 - val_accuracy: 0.6810 - val_loss: 0.8807 - learning_rate: 2.5000e-05\n",
            "Epoch 476/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6502 - loss: 0.9558 - val_accuracy: 0.6897 - val_loss: 0.8779 - learning_rate: 2.5000e-05\n",
            "Epoch 477/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6470 - loss: 0.9932 - val_accuracy: 0.6810 - val_loss: 0.8789 - learning_rate: 2.5000e-05\n",
            "Epoch 478/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6883 - loss: 0.9170 - val_accuracy: 0.6810 - val_loss: 0.8783 - learning_rate: 2.5000e-05\n",
            "Epoch 479/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6574 - loss: 0.9778 - val_accuracy: 0.6810 - val_loss: 0.8783 - learning_rate: 2.5000e-05\n",
            "Epoch 480/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.8796 - val_accuracy: 0.6810 - val_loss: 0.8800 - learning_rate: 2.5000e-05\n",
            "Epoch 481/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6716 - loss: 0.8776 - val_accuracy: 0.6897 - val_loss: 0.8815 - learning_rate: 2.5000e-05\n",
            "Epoch 482/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6584 - loss: 0.9279 - val_accuracy: 0.6897 - val_loss: 0.8813 - learning_rate: 2.5000e-05\n",
            "Epoch 483/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6599 - loss: 0.9328 - val_accuracy: 0.6897 - val_loss: 0.8801 - learning_rate: 2.5000e-05\n",
            "Epoch 484/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6500 - loss: 0.9699 - val_accuracy: 0.6897 - val_loss: 0.8789 - learning_rate: 2.5000e-05\n",
            "Epoch 485/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.8822 - val_accuracy: 0.6983 - val_loss: 0.8797 - learning_rate: 2.5000e-05\n",
            "Epoch 486/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.9299 - val_accuracy: 0.6897 - val_loss: 0.8800 - learning_rate: 2.5000e-05\n",
            "Epoch 487/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: 0.9615 - val_accuracy: 0.6897 - val_loss: 0.8790 - learning_rate: 1.2500e-05\n",
            "Epoch 488/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 0.8935 - val_accuracy: 0.6983 - val_loss: 0.8805 - learning_rate: 1.2500e-05\n",
            "Epoch 489/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6504 - loss: 0.9837 - val_accuracy: 0.6897 - val_loss: 0.8799 - learning_rate: 1.2500e-05\n",
            "Epoch 490/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6573 - loss: 0.9531 - val_accuracy: 0.6897 - val_loss: 0.8789 - learning_rate: 1.2500e-05\n",
            "Epoch 491/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6884 - loss: 0.9222 - val_accuracy: 0.6897 - val_loss: 0.8787 - learning_rate: 1.2500e-05\n",
            "Epoch 492/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6763 - loss: 0.8853 - val_accuracy: 0.6897 - val_loss: 0.8786 - learning_rate: 1.2500e-05\n",
            "Epoch 493/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 0.9000 - val_accuracy: 0.6897 - val_loss: 0.8800 - learning_rate: 1.2500e-05\n",
            "Epoch 494/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6635 - loss: 0.9087 - val_accuracy: 0.6897 - val_loss: 0.8796 - learning_rate: 1.2500e-05\n",
            "Epoch 495/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6788 - loss: 0.9094 - val_accuracy: 0.6810 - val_loss: 0.8788 - learning_rate: 1.2500e-05\n",
            "Epoch 496/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6774 - loss: 0.8751 - val_accuracy: 0.6724 - val_loss: 0.8799 - learning_rate: 1.2500e-05\n",
            "Epoch 497/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6795 - loss: 0.8763 - val_accuracy: 0.6724 - val_loss: 0.8792 - learning_rate: 6.2500e-06\n",
            "Epoch 498/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6597 - loss: 0.9127 - val_accuracy: 0.6724 - val_loss: 0.8782 - learning_rate: 6.2500e-06\n",
            "Epoch 499/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6433 - loss: 0.9713 - val_accuracy: 0.6810 - val_loss: 0.8790 - learning_rate: 6.2500e-06\n",
            "Epoch 500/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.8746 - val_accuracy: 0.6810 - val_loss: 0.8781 - learning_rate: 6.2500e-06\n",
            "Epoch 501/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6508 - loss: 0.9497 - val_accuracy: 0.6897 - val_loss: 0.8781 - learning_rate: 6.2500e-06\n",
            "Epoch 502/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6728 - loss: 0.8975 - val_accuracy: 0.6810 - val_loss: 0.8792 - learning_rate: 6.2500e-06\n",
            "Epoch 503/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6765 - loss: 0.9508 - val_accuracy: 0.6897 - val_loss: 0.8777 - learning_rate: 6.2500e-06\n",
            "Epoch 504/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6517 - loss: 0.9024 - val_accuracy: 0.6897 - val_loss: 0.8800 - learning_rate: 6.2500e-06\n",
            "Epoch 505/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6610 - loss: 0.9173 - val_accuracy: 0.6897 - val_loss: 0.8781 - learning_rate: 6.2500e-06\n",
            "Epoch 506/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.9017 - val_accuracy: 0.6897 - val_loss: 0.8789 - learning_rate: 6.2500e-06\n",
            "Epoch 507/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6644 - loss: 0.9583 - val_accuracy: 0.6810 - val_loss: 0.8806 - learning_rate: 6.2500e-06\n",
            "Epoch 508/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6810 - loss: 0.8724 - val_accuracy: 0.6810 - val_loss: 0.8804 - learning_rate: 6.2500e-06\n",
            "Epoch 509/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6950 - loss: 0.8634 - val_accuracy: 0.6810 - val_loss: 0.8810 - learning_rate: 6.2500e-06\n",
            "Epoch 510/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 0.9409 - val_accuracy: 0.6810 - val_loss: 0.8787 - learning_rate: 6.2500e-06\n",
            "Epoch 511/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6674 - loss: 0.8794 - val_accuracy: 0.6810 - val_loss: 0.8780 - learning_rate: 6.2500e-06\n",
            "Epoch 512/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6513 - loss: 0.9722 - val_accuracy: 0.6810 - val_loss: 0.8789 - learning_rate: 6.2500e-06\n",
            "Epoch 513/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6540 - loss: 0.9147 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 6.2500e-06\n",
            "Epoch 514/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6663 - loss: 0.9445 - val_accuracy: 0.6810 - val_loss: 0.8762 - learning_rate: 6.2500e-06\n",
            "Epoch 515/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6533 - loss: 0.9149 - val_accuracy: 0.6810 - val_loss: 0.8780 - learning_rate: 6.2500e-06\n",
            "Epoch 516/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6918 - loss: 0.8792 - val_accuracy: 0.6810 - val_loss: 0.8787 - learning_rate: 6.2500e-06\n",
            "Epoch 517/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 0.9507 - val_accuracy: 0.6810 - val_loss: 0.8785 - learning_rate: 6.2500e-06\n",
            "Epoch 518/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6684 - loss: 0.9161 - val_accuracy: 0.6810 - val_loss: 0.8781 - learning_rate: 6.2500e-06\n",
            "Epoch 519/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6745 - loss: 0.9091 - val_accuracy: 0.6724 - val_loss: 0.8781 - learning_rate: 6.2500e-06\n",
            "Epoch 520/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6876 - loss: 0.9239 - val_accuracy: 0.6724 - val_loss: 0.8772 - learning_rate: 6.2500e-06\n",
            "Epoch 521/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7011 - loss: 0.8539 - val_accuracy: 0.6810 - val_loss: 0.8751 - learning_rate: 6.2500e-06\n",
            "Epoch 522/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.8620 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 6.2500e-06\n",
            "Epoch 523/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6733 - loss: 0.9115 - val_accuracy: 0.6897 - val_loss: 0.8768 - learning_rate: 6.2500e-06\n",
            "Epoch 524/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6783 - loss: 0.8713 - val_accuracy: 0.6810 - val_loss: 0.8760 - learning_rate: 6.2500e-06\n",
            "Epoch 525/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6425 - loss: 0.9373 - val_accuracy: 0.6810 - val_loss: 0.8768 - learning_rate: 6.2500e-06\n",
            "Epoch 526/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.8998 - val_accuracy: 0.6810 - val_loss: 0.8785 - learning_rate: 6.2500e-06\n",
            "Epoch 527/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.9436 - val_accuracy: 0.6810 - val_loss: 0.8768 - learning_rate: 6.2500e-06\n",
            "Epoch 528/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.8769 - val_accuracy: 0.6810 - val_loss: 0.8768 - learning_rate: 6.2500e-06\n",
            "Epoch 529/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6793 - loss: 0.8795 - val_accuracy: 0.6810 - val_loss: 0.8766 - learning_rate: 6.2500e-06\n",
            "Epoch 530/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6629 - loss: 0.9154 - val_accuracy: 0.6810 - val_loss: 0.8784 - learning_rate: 6.2500e-06\n",
            "Epoch 531/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.9136 - val_accuracy: 0.6810 - val_loss: 0.8776 - learning_rate: 6.2500e-06\n",
            "Epoch 532/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6532 - loss: 0.9559 - val_accuracy: 0.6810 - val_loss: 0.8775 - learning_rate: 3.1250e-06\n",
            "Epoch 533/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6685 - loss: 0.9359 - val_accuracy: 0.6897 - val_loss: 0.8786 - learning_rate: 3.1250e-06\n",
            "Epoch 534/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.8814 - val_accuracy: 0.6810 - val_loss: 0.8775 - learning_rate: 3.1250e-06\n",
            "Epoch 535/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6472 - loss: 0.9286 - val_accuracy: 0.6810 - val_loss: 0.8778 - learning_rate: 3.1250e-06\n",
            "Epoch 536/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6632 - loss: 0.9289 - val_accuracy: 0.6810 - val_loss: 0.8782 - learning_rate: 3.1250e-06\n",
            "Epoch 537/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.9673 - val_accuracy: 0.6810 - val_loss: 0.8756 - learning_rate: 3.1250e-06\n",
            "Epoch 538/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6850 - loss: 0.8757 - val_accuracy: 0.6810 - val_loss: 0.8756 - learning_rate: 3.1250e-06\n",
            "Epoch 539/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6578 - loss: 0.9234 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 3.1250e-06\n",
            "Epoch 540/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.8963 - val_accuracy: 0.6810 - val_loss: 0.8765 - learning_rate: 3.1250e-06\n",
            "Epoch 541/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.9340 - val_accuracy: 0.6897 - val_loss: 0.8773 - learning_rate: 3.1250e-06\n",
            "Epoch 542/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6818 - loss: 0.9039 - val_accuracy: 0.6810 - val_loss: 0.8754 - learning_rate: 1.5625e-06\n",
            "Epoch 543/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6831 - loss: 0.9417 - val_accuracy: 0.6810 - val_loss: 0.8741 - learning_rate: 1.5625e-06\n",
            "Epoch 544/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6610 - loss: 0.9393 - val_accuracy: 0.6810 - val_loss: 0.8753 - learning_rate: 1.5625e-06\n",
            "Epoch 545/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 0.9470 - val_accuracy: 0.6810 - val_loss: 0.8752 - learning_rate: 1.5625e-06\n",
            "Epoch 546/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6865 - loss: 0.8899 - val_accuracy: 0.6810 - val_loss: 0.8747 - learning_rate: 1.5625e-06\n",
            "Epoch 547/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6620 - loss: 0.9259 - val_accuracy: 0.6810 - val_loss: 0.8749 - learning_rate: 1.5625e-06\n",
            "Epoch 548/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.9097 - val_accuracy: 0.6897 - val_loss: 0.8745 - learning_rate: 1.5625e-06\n",
            "Epoch 549/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.8397 - val_accuracy: 0.6897 - val_loss: 0.8748 - learning_rate: 1.5625e-06\n",
            "Epoch 550/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7102 - loss: 0.8490 - val_accuracy: 0.6897 - val_loss: 0.8749 - learning_rate: 1.5625e-06\n",
            "Epoch 551/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.8973 - val_accuracy: 0.6810 - val_loss: 0.8740 - learning_rate: 1.5625e-06\n",
            "Epoch 552/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6723 - loss: 0.8607 - val_accuracy: 0.6897 - val_loss: 0.8735 - learning_rate: 1.5625e-06\n",
            "Epoch 553/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6684 - loss: 0.9096 - val_accuracy: 0.6897 - val_loss: 0.8757 - learning_rate: 1.5625e-06\n",
            "Epoch 554/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6739 - loss: 0.9001 - val_accuracy: 0.6897 - val_loss: 0.8753 - learning_rate: 1.5625e-06\n",
            "Epoch 555/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6547 - loss: 0.8924 - val_accuracy: 0.6897 - val_loss: 0.8758 - learning_rate: 1.5625e-06\n",
            "Epoch 556/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6468 - loss: 0.9564 - val_accuracy: 0.6897 - val_loss: 0.8767 - learning_rate: 1.5625e-06\n",
            "Epoch 557/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6837 - loss: 0.8784 - val_accuracy: 0.6897 - val_loss: 0.8774 - learning_rate: 1.5625e-06\n",
            "Epoch 558/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 0.9310 - val_accuracy: 0.6897 - val_loss: 0.8778 - learning_rate: 1.5625e-06\n",
            "Epoch 559/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.8757 - val_accuracy: 0.6897 - val_loss: 0.8777 - learning_rate: 1.5625e-06\n",
            "Epoch 560/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6896 - loss: 0.8480 - val_accuracy: 0.6810 - val_loss: 0.8783 - learning_rate: 1.5625e-06\n",
            "Epoch 561/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.8331 - val_accuracy: 0.6897 - val_loss: 0.8786 - learning_rate: 1.5625e-06\n",
            "Epoch 562/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.9340 - val_accuracy: 0.6810 - val_loss: 0.8797 - learning_rate: 1.5625e-06\n",
            "Epoch 563/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6663 - loss: 0.9118 - val_accuracy: 0.6810 - val_loss: 0.8786 - learning_rate: 1.0000e-06\n",
            "Epoch 564/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7098 - loss: 0.8643 - val_accuracy: 0.6810 - val_loss: 0.8780 - learning_rate: 1.0000e-06\n",
            "Epoch 565/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6604 - loss: 0.9901 - val_accuracy: 0.6810 - val_loss: 0.8787 - learning_rate: 1.0000e-06\n",
            "Epoch 566/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6488 - loss: 0.9464 - val_accuracy: 0.6810 - val_loss: 0.8785 - learning_rate: 1.0000e-06\n",
            "Epoch 567/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.9344 - val_accuracy: 0.6810 - val_loss: 0.8779 - learning_rate: 1.0000e-06\n",
            "Epoch 568/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6784 - loss: 0.8863 - val_accuracy: 0.6810 - val_loss: 0.8765 - learning_rate: 1.0000e-06\n",
            "Epoch 569/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6684 - loss: 0.9005 - val_accuracy: 0.6810 - val_loss: 0.8756 - learning_rate: 1.0000e-06\n",
            "Epoch 570/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.9045 - val_accuracy: 0.6810 - val_loss: 0.8751 - learning_rate: 1.0000e-06\n",
            "Epoch 571/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 0.9176 - val_accuracy: 0.6810 - val_loss: 0.8766 - learning_rate: 1.0000e-06\n",
            "Epoch 572/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6321 - loss: 0.9951 - val_accuracy: 0.6897 - val_loss: 0.8759 - learning_rate: 1.0000e-06\n",
            "Epoch 573/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6934 - loss: 0.9153 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 1.0000e-06\n",
            "Epoch 574/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6592 - loss: 0.9036 - val_accuracy: 0.6810 - val_loss: 0.8748 - learning_rate: 1.0000e-06\n",
            "Epoch 575/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.8906 - val_accuracy: 0.6810 - val_loss: 0.8753 - learning_rate: 1.0000e-06\n",
            "Epoch 576/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6662 - loss: 0.9231 - val_accuracy: 0.6810 - val_loss: 0.8762 - learning_rate: 1.0000e-06\n",
            "Epoch 577/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.8607 - val_accuracy: 0.6810 - val_loss: 0.8768 - learning_rate: 1.0000e-06\n",
            "Epoch 578/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6872 - loss: 0.8825 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 1.0000e-06\n",
            "Epoch 579/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6809 - loss: 0.9402 - val_accuracy: 0.6810 - val_loss: 0.8767 - learning_rate: 1.0000e-06\n",
            "Epoch 580/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6923 - loss: 0.8473 - val_accuracy: 0.6810 - val_loss: 0.8764 - learning_rate: 1.0000e-06\n",
            "Epoch 581/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 0.9269 - val_accuracy: 0.6897 - val_loss: 0.8770 - learning_rate: 1.0000e-06\n",
            "Epoch 582/650\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6245 - loss: 1.0126 - val_accuracy: 0.6983 - val_loss: 0.8755 - learning_rate: 1.0000e-06\n",
            "Test Accuracy: 62.15%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a Predictive System (Testing Some Audio Data)\n",
        "\n",
        "filename='/content/audio_speech_actors_01-24/Actor_06/03-01-06-02-01-02-06.wav'\n",
        "audio,sample_rate=librosa.load(filename)\n",
        "mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled = np.mean(mfccs.T, axis=0)  # Take the mean of MFCCs over time\n",
        "print(mfccs_scaled)\n",
        "\n",
        "mfccs_scaled_reshaped=mfccs_scaled.reshape(1,-1)\n",
        "print(mfccs_scaled_reshaped.shape)\n",
        "predicted_label=model.predict(mfccs_scaled_reshaped)\n",
        "\n",
        "# Get the index of the class with the highest probability\n",
        "predicted_index = np.argmax(predicted_label, axis=1)\n",
        "\n",
        "prediction_class=labelencoder.inverse_transform(predicted_index)\n",
        "print(f\"Predicted Emotion: {prediction_class[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkCNcBjmJ9uT",
        "outputId": "907f482d-c0ab-42a2-9443-6459ca5c36f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.7622406e+02  5.6681504e+00 -4.9888969e+01 -1.2137798e+01\n",
            " -1.6262897e+01 -2.2261307e+01 -1.8829643e+01 -3.7612352e+00\n",
            " -4.0016875e+00  2.0488115e+01  1.1183810e+01  6.0422525e+00\n",
            "  1.8064806e+00 -7.6966333e+00 -9.7748804e+00  8.4445751e-01\n",
            "  2.2397048e+00  1.6709417e+00 -2.8776655e+00  3.3189039e+00\n",
            "  8.8195601e+00 -3.1297016e+00 -6.6021667e+00  2.1168038e-01\n",
            " -2.1119630e+00 -1.3039175e-01  2.8393514e+00  4.9852858e+00\n",
            " -1.6064435e+00  4.8101797e+00  2.2546568e+00  1.3394228e+00\n",
            "  2.3413353e+00  6.7924485e+00  1.5943357e+00  5.1745687e+00\n",
            "  7.7707714e-01  1.5902046e+00  1.7126160e+00  2.4909937e+00]\n",
            "(1, 40)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Predicted Emotion: calm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xNbsGdeCQf6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}